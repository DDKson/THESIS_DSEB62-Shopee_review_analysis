{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFFePzBhuh4O",
        "outputId": "f4ab2392-0e96-4ed2-a500-69a00ee4d685"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for py_vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.6/259.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ]
        }
      ],
      "source": [
        "! pip install --quiet underthesea\n",
        "! pip install --quiet vncorenlp\n",
        "! pip install --quiet py_vncorenlp\n",
        "! pip install --quiet python-rdrsegmenter\n",
        "! pip install scikit-multilearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KRr76qRsZY7T"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uhS3Y1BK0LHE",
        "outputId": "a3b166a6-92b7-4388-b91c-d78f68170d53"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'train = pd.read_excel(\"/content/drive/MyDrive/Thesis: Topic Modelling/Data/Splitted data/train.xlsx\")\\ntest = pd.read_excel(\"/content/drive/MyDrive/Thesis: Topic Modelling/Data/Splitted data/test.xlsx\")\\n\\ntrain, valid = train_test_split(train, test_size = 0.1, random_state = 60)\\ntrain.to_excel(\"/content/drive/MyDrive/Thesis: Topic Modelling/Data/Splitted data/train.xlsx\")\\nvalid.to_excel(\"/content/drive/MyDrive/Thesis: Topic Modelling/Data/Splitted data/valid.xlsx\")'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"train = pd.read_excel(\"/content/drive/MyDrive/Thesis: Topic Modelling/Data/Splitted data/train.xlsx\")\n",
        "test = pd.read_excel(\"/content/drive/MyDrive/Thesis: Topic Modelling/Data/Splitted data/test.xlsx\")\n",
        "\n",
        "train, valid = train_test_split(train, test_size = 0.1, random_state = 60)\n",
        "train.to_excel(\"/content/drive/MyDrive/Thesis: Topic Modelling/Data/Splitted data/train.xlsx\")\n",
        "valid.to_excel(\"/content/drive/MyDrive/Thesis: Topic Modelling/Data/Splitted data/valid.xlsx\")\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Njb23nhzvFof"
      },
      "outputs": [],
      "source": [
        "# see data preprocessing steps at link:\n",
        "# https://colab.research.google.com/drive/1AuvWD-Lo6UIjyb_fmjxGB1zLZWZQ7GFf?ouid=115125045212634117084&usp=drive_link\n",
        "from distutils.dir_util import copy_tree\n",
        "copy_tree(\"/content/drive/MyDrive/Thesis: Topic Modelling/Code/utils\", \"./utils/\")\n",
        "\n",
        "from utils.data_preprocessing_v2 import *\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from underthesea import word_tokenize, text_normalize\n",
        "from gensim.models import word2vec\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skmultilearn.problem_transform import BinaryRelevance\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, confusion_matrix\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import xgboost as xgb\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from scipy.stats import mode\n",
        "from vncorenlp import VnCoreNLP\n",
        "from sklearn.metrics import hamming_loss\n",
        "from sklearn.multioutput import ClassifierChain\n",
        "\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Thesis: Topic Modelling/Code/utils/vietnamese-stopwords.txt\") as f:\n",
        "    STOPWORDS = f.readlines()\n",
        "    STOPWORDS = [remove_all_tag(i) for i in STOPWORDS]\n",
        "\n",
        "\n",
        "def evaluate(y_true, y_pred, eval_individual = True, model_name = \"\"):\n",
        "  label_cols = [\"Quality\", \"Pack\", \"Serve\", \"Shipping\", \"Price\", \"Other\"]\n",
        "  print(f\"Classification report from {model_name}\")\n",
        "  print(classification_report(y_true[label_cols], y_pred))\n",
        "  print('Hamming Loss: ', round(hamming_loss(y_true, y_pred),3))\n",
        "  if eval_individual:\n",
        "    for i in range(len(label_cols)):\n",
        "      print(f\"classification report of {label_cols[i]}\")\n",
        "      print(classification_report(y_true[label_cols[i]], y_pred[:, i]))\n",
        "\n",
        "\n",
        "def evaluate_chain(model, X_train, y_train, X_test, y_test, predict_proba = True):\n",
        "  chains = [ClassifierChain(model, order=\"random\", random_state=i) for i in range(10)]\n",
        "  ovr = OneVsRestClassifier(model)\n",
        "  ovr.fit(X_train, y_train)\n",
        "  Y_pred_ovr = ovr.predict(X_test)\n",
        "  ovr_hamming_loss = hamming_loss(y_test, Y_pred_ovr)\n",
        "  for chain in chains:\n",
        "    chain.fit(X_train, y_train)\n",
        "  if predict_proba:\n",
        "    Y_pred_chains = np.array([chain.predict_proba(X_test) for chain in chains])\n",
        "    Y_pred_ensemble = Y_pred_chains.mean(axis=0)\n",
        "    Y_pred_ensemble = Y_pred_ensemble >= 0.5\n",
        "  else:\n",
        "    Y_pred_chains = np.array([chain.predict(X_test) for chain in chains])\n",
        "    Y_pred_ensemble = mode(Y_pred_chains, axis = 0)[0]\n",
        "  chain_hamming_loss = [\n",
        "      hamming_loss(y_test, Y_pred_chain >= 0.5)\n",
        "      for Y_pred_chain in Y_pred_chains\n",
        "  ]\n",
        "  ensemble_hamming_loss = hamming_loss(y_test, Y_pred_ensemble)\n",
        "  scores = [ovr_hamming_loss] + chain_hamming_loss + [ensemble_hamming_loss]\n",
        "  evaluate(y_test, Y_pred_ovr, eval_individual = False, model_name = \"One Vs Rest model\")\n",
        "  evaluate(y_test, Y_pred_ensemble, eval_individual = False, model_name = \"Ensemble model from classifier chain\")\n",
        "  return scores\n",
        "\n",
        "def train_ovr(base_model, X_train, y_train):\n",
        "  ovr = OneVsRestClassifier(base_model)\n",
        "  ovr.fit(X_train, y_train)\n",
        "  return ovr\n",
        "\n",
        "def displayConfusionMatrix(y_true, y_pred, label = \"Dataset\"):\n",
        "    disp = ConfusionMatrixDisplay.from_predictions(\n",
        "        y_true,\n",
        "        y_pred, #np.argmax(y_pred, axis=1),\n",
        "        display_labels=[\"0\",\"1\"],\n",
        "        cmap=plt.cm.Blues\n",
        "    )\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    f1_score = tp / (tp+((fn+fp)/2))\n",
        "    disp.ax_.set_title(\"Confusion Matrix on \" + f\" {label} -- F1 Score: \" + str(f1_score.round(2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dtMgY3LpEgkW",
        "outputId": "41a2c335-44f0-47c1-b335-6069ee5e9057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12240, 11)\n",
            "(3401, 10)\n",
            "(1361, 11)\n"
          ]
        }
      ],
      "source": [
        "train = pd.read_excel(\"/content/drive/MyDrive/Thesis: Topic Modelling/Data/Splitted data/train.xlsx\")\n",
        "test = pd.read_excel(\"/content/drive/MyDrive/Thesis: Topic Modelling/Data/Splitted data/test.xlsx\")\n",
        "valid = pd.read_excel(\"/content/drive/MyDrive/Thesis: Topic Modelling/Data/Splitted data/valid.xlsx\")\n",
        "\n",
        "for i in [train,test, valid]:\n",
        "  print(i.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mc8SCKmI1t2P"
      },
      "outputs": [],
      "source": [
        "labels_cols = [\"Quality\", \"Pack\", \"Serve\", \"Shipping\", \"Price\", \"Other\"]\n",
        "train = pd.read_excel(\"/content/drive/MyDrive/Thesis: Topic Modelling/Data/Splitted data/train.xlsx\")\n",
        "train[\"comment\"] = train[\"comment\"].astype(str)\n",
        "train[\"clean_comment\"] = train[\"comment\"].apply(lambda x: cleaning(x))\n",
        "X_train = train[\"clean_comment\"]\n",
        "y_train = train[labels_cols]\n",
        "\n",
        "test = pd.read_excel(\"/content/drive/MyDrive/Thesis: Topic Modelling/Data/Splitted data/test.xlsx\")\n",
        "test[\"comment\"] = test[\"comment\"].astype(str)\n",
        "test[\"clean_comment\"] = test[\"comment\"].apply(lambda x: cleaning(x))\n",
        "X_test = test[\"clean_comment\"]\n",
        "y_test = test[labels_cols]\n",
        "\n",
        "valid = pd.read_excel(\"/content/drive/MyDrive/Thesis: Topic Modelling/Data/Splitted data/test.xlsx\")\n",
        "valid[\"comment\"] = valid[\"comment\"].astype(str)\n",
        "valid[\"clean_comment\"] = valid[\"comment\"].apply(lambda x: cleaning(x))\n",
        "X_valid = valid[\"clean_comment\"]\n",
        "y_valid = valid[labels_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PAtDvl4IYCR",
        "outputId": "5e55c30b-2bf6-4866-e208-60faaf1c7e7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'tfidf__max_df': 0.75, 'tfidf__min_df': 4, 'tfidf__ngram_range': (1, 1), 'tfidf__smooth_idf': True, 'tfidf__stop_words': ['a lô ', 'a ha ', 'ai ', 'ai ai ', 'ai nấy ', 'ai đó ', 'alô ', 'amen ', 'anh ', 'anh ấy ', 'ba ', 'ba ba ', 'ba bản ', 'ba cùng ', 'ba họ ', 'ba ngày ', 'ba ngôi ', 'ba tăng ', 'bao giờ ', 'bao lâu ', 'bao nhiêu ', 'bao nả ', 'bay biến ', 'biết ', 'biết bao ', 'biết bao nhiêu ', 'biết chắc ', 'biết chừng nào ', 'biết mình ', 'biết mấy ', 'biết thế ', 'biết trước ', 'biết việc ', 'biết đâu ', 'biết đâu chừng ', 'biết đâu đấy ', 'biết được ', 'buổi ', 'buổi làm ', 'buổi mới ', 'buổi ngày ', 'buổi sớm ', 'bà ', 'bà ấy ', 'bài ', 'bài bác ', 'bài bỏ ', 'bài cái ', 'bác ', 'bán ', 'bán cấp ', 'bán dạ ', 'bán thế ', 'bây bẩy ', 'bây chừ ', 'bây giờ ', 'bây nhiêu ', 'bèn ', 'béng ', 'bên ', 'bên bị ', 'bên có ', 'bên cạnh ', 'bông ', 'bước ', 'bước khỏi ', 'bước tới ', 'bước đi ', 'bạn ', 'bản ', 'bản bộ ', 'bản riêng ', 'bản thân ', 'bản ý ', 'bất chợt ', 'bất cứ ', 'bất giác ', 'bất kì ', 'bất kể ', 'bất kỳ ', 'bất luận ', 'bất ngờ ', 'bất nhược ', 'bất quá ', 'bất quá chỉ ', 'bất thình lình ', 'bất tử ', 'bất đồ ', 'bấy ', 'bấy chầy ', 'bấy chừ ', 'bấy giờ ', 'bấy lâu ', 'bấy lâu nay ', 'bấy nay ', 'bấy nhiêu ', 'bập bà bập bõm ', 'bập bõm ', 'bắt đầu ', 'bắt đầu từ ', 'bằng ', 'bằng cứ ', 'bằng không ', 'bằng người ', 'bằng nhau ', 'bằng như ', 'bằng nào ', 'bằng nấy ', 'bằng vào ', 'bằng được ', 'bằng ấy ', 'bển ', 'bệt ', 'bị ', 'bị chú ', 'bị vì ', 'bỏ ', 'bỏ bà ', 'bỏ cha ', 'bỏ cuộc ', 'bỏ không ', 'bỏ lại ', 'bỏ mình ', 'bỏ mất ', 'bỏ mẹ ', 'bỏ nhỏ ', 'bỏ quá ', 'bỏ ra ', 'bỏ riêng ', 'bỏ việc ', 'bỏ xa ', 'bỗng ', 'bỗng chốc ', 'bỗng dưng ', 'bỗng không ', 'bỗng nhiên ', 'bỗng nhưng ', 'bỗng thấy ', 'bỗng đâu ', 'bộ ', 'bộ thuộc ', 'bộ điều ', 'bội phần ', 'bớ ', 'bởi ', 'bởi ai ', 'bởi chưng ', 'bởi nhưng ', 'bởi sao ', 'bởi thế ', 'bởi thế cho nên ', 'bởi tại ', 'bởi vì ', 'bởi vậy ', 'bởi đâu ', 'bức ', 'cao ', 'cao lâu ', 'cao ráo ', 'cao răng ', 'cao sang ', 'cao số ', 'cao thấp ', 'cao thế ', 'cao xa ', 'cha ', 'cha chả ', 'chao ôi ', 'chia sẻ ', 'chiếc ', 'cho ', 'cho biết ', 'cho chắc ', 'cho hay ', 'cho nhau ', 'cho nên ', 'cho rằng ', 'cho rồi ', 'cho thấy ', 'cho tin ', 'cho tới ', 'cho tới khi ', 'cho về ', 'cho ăn ', 'cho đang ', 'cho được ', 'cho đến ', 'cho đến khi ', 'cho đến nỗi ', 'choa ', 'chu cha ', 'chui cha ', 'chung ', 'chung cho ', 'chung chung ', 'chung cuộc ', 'chung cục ', 'chung nhau ', 'chung qui ', 'chung quy ', 'chung quy lại ', 'chung ái ', 'chuyển ', 'chuyển tự ', 'chuyển đạt ', 'chuyện ', 'chuẩn bị ', 'chành chạnh ', 'chí chết ', 'chính ', 'chính bản ', 'chính giữa ', 'chính là ', 'chính thị ', 'chính điểm ', 'chùn chùn ', 'chùn chũn ', 'chú ', 'chú dẫn ', 'chú khách ', 'chú mày ', 'chú mình ', 'chúng ', 'chúng mình ', 'chúng ta ', 'chúng tôi ', 'chúng ông ', 'chăn chắn ', 'chăng ', 'chăng chắc ', 'chăng nữa ', 'chơi ', 'chơi họ ', 'chưa ', 'chưa bao giờ ', 'chưa chắc ', 'chưa có ', 'chưa cần ', 'chưa dùng ', 'chưa dễ ', 'chưa kể ', 'chưa tính ', 'chưa từng ', 'chầm chập ', 'chậc ', 'chắc ', 'chắc chắn ', 'chắc dạ ', 'chắc hẳn ', 'chắc lòng ', 'chắc người ', 'chắc vào ', 'chắc ăn ', 'chẳng lẽ ', 'chẳng những ', 'chẳng nữa ', 'chẳng phải ', 'chết nỗi ', 'chết thật ', 'chết tiệt ', 'chỉ ', 'chỉ chính ', 'chỉ có ', 'chỉ là ', 'chỉ tên ', 'chỉn ', 'chị ', 'chị bộ ', 'chị ấy ', 'chịu ', 'chịu chưa ', 'chịu lời ', 'chịu tốt ', 'chịu ăn ', 'chọn ', 'chọn bên ', 'chọn ra ', 'chốc chốc ', 'chớ ', 'chớ chi ', 'chớ gì ', 'chớ không ', 'chớ kể ', 'chớ như ', 'chợt ', 'chợt nghe ', 'chợt nhìn ', 'chủn ', 'chứ ', 'chứ ai ', 'chứ còn ', 'chứ gì ', 'chứ không ', 'chứ không phải ', 'chứ lại ', 'chứ lị ', 'chứ như ', 'chứ sao ', 'coi bộ ', 'coi mòi ', 'con ', 'con con ', 'con dạ ', 'con nhà ', 'con tính ', 'cu cậu ', 'cuối ', 'cuối cùng ', 'cuối điểm ', 'cuốn ', 'cuộc ', 'càng ', 'càng càng ', 'càng hay ', 'cá nhân ', 'các ', 'các cậu ', 'cách ', 'cách bức ', 'cách không ', 'cách nhau ', 'cách đều ', 'cái ', 'cái gì ', 'cái họ ', 'cái đã ', 'cái đó ', 'cái ấy ', 'câu hỏi ', 'cây ', 'cây nước ', 'còn ', 'còn như ', 'còn nữa ', 'còn thời gian ', 'còn về ', 'có ', 'có ai ', 'có chuyện ', 'có chăng ', 'có chăng là ', 'có chứ ', 'có cơ ', 'có dễ ', 'có họ ', 'có khi ', 'có ngày ', 'có người ', 'có nhiều ', 'có nhà ', 'có phải ', 'có số ', 'có tháng ', 'có thế ', 'có thể ', 'có vẻ ', 'có ý ', 'có ăn ', 'có điều ', 'có điều kiện ', 'có đáng ', 'có đâu ', 'có được ', 'cóc khô ', 'cô ', 'cô mình ', 'cô quả ', 'cô tăng ', 'cô ấy ', 'công nhiên ', 'cùng ', 'cùng chung ', 'cùng cực ', 'cùng nhau ', 'cùng tuổi ', 'cùng tột ', 'cùng với ', 'cùng ăn ', 'căn ', 'căn cái ', 'căn cắt ', 'căn tính ', 'cũng ', 'cũng như ', 'cũng nên ', 'cũng thế ', 'cũng vậy ', 'cũng vậy thôi ', 'cũng được ', 'cơ ', 'cơ chỉ ', 'cơ chừng ', 'cơ cùng ', 'cơ dẫn ', 'cơ hồ ', 'cơ hội ', 'cơ mà ', 'cơn ', 'cả ', 'cả nghe ', 'cả nghĩ ', 'cả ngày ', 'cả người ', 'cả nhà ', 'cả năm ', 'cả thảy ', 'cả thể ', 'cả tin ', 'cả ăn ', 'cả đến ', 'cảm thấy ', 'cảm ơn ', 'cấp ', 'cấp số ', 'cấp trực tiếp ', 'cần ', 'cần cấp ', 'cần gì ', 'cần số ', 'cật lực ', 'cật sức ', 'cậu ', 'cổ lai ', 'cụ thể ', 'cụ thể là ', 'cụ thể như ', 'của ', 'của ngọt ', 'của tin ', 'cứ ', 'cứ như ', 'cứ việc ', 'cứ điểm ', 'cực lực ', 'do ', 'do vì ', 'do vậy ', 'do đó ', 'duy ', 'duy chỉ ', 'duy có ', 'dài ', 'dài lời ', 'dài ra ', 'dành ', 'dành dành ', 'dào ', 'dì ', 'dù ', 'dù cho ', 'dù dì ', 'dù gì ', 'dù rằng ', 'dù sao ', 'dùng ', 'dùng cho ', 'dùng hết ', 'dùng làm ', 'dùng đến ', 'dưới ', 'dưới nước ', 'dạ ', 'dạ bán ', 'dạ con ', 'dạ dài ', 'dạ dạ ', 'dạ khách ', 'dần dà ', 'dần dần ', 'dầu sao ', 'dẫn ', 'dẫu ', 'dẫu mà ', 'dẫu rằng ', 'dẫu sao ', 'dễ ', 'dễ dùng ', 'dễ gì ', 'dễ khiến ', 'dễ nghe ', 'dễ ngươi ', 'dễ như chơi ', 'dễ sợ ', 'dễ sử dụng ', 'dễ thường ', 'dễ thấy ', 'dễ ăn ', 'dễ đâu ', 'dở chừng ', 'dữ ', 'dữ cách ', 'em ', 'em em ', 'giá trị ', 'giá trị thực tế ', 'giảm ', 'giảm chính ', 'giảm thấp ', 'giảm thế ', 'giống ', 'giống người ', 'giống nhau ', 'giống như ', 'giờ ', 'giờ lâu ', 'giờ này ', 'giờ đi ', 'giờ đây ', 'giờ đến ', 'giữ ', 'giữ lấy ', 'giữ ý ', 'giữa ', 'giữa lúc ', 'gây ', 'gây cho ', 'gây giống ', 'gây ra ', 'gây thêm ', 'gì ', 'gì gì ', 'gì đó ', 'gần ', 'gần bên ', 'gần hết ', 'gần ngày ', 'gần như ', 'gần xa ', 'gần đây ', 'gần đến ', 'gặp ', 'gặp khó khăn ', 'gặp phải ', 'gồm ', 'hay ', 'hay biết ', 'hay hay ', 'hay không ', 'hay là ', 'hay làm ', 'hay nhỉ ', 'hay nói ', 'hay sao ', 'hay tin ', 'hay đâu ', 'hiểu ', 'hiện nay ', 'hiện tại ', 'hoàn toàn ', 'hoặc ', 'hoặc là ', 'hãy ', 'hãy còn ', 'hơn ', 'hơn cả ', 'hơn hết ', 'hơn là ', 'hơn nữa ', 'hơn trước ', 'hầu hết ', 'hết ', 'hết chuyện ', 'hết cả ', 'hết của ', 'hết nói ', 'hết ráo ', 'hết rồi ', 'hết ý ', 'họ ', 'họ gần ', 'họ xa ', 'hỏi ', 'hỏi lại ', 'hỏi xem ', 'hỏi xin ', 'hỗ trợ ', 'khi ', 'khi khác ', 'khi không ', 'khi nào ', 'khi nên ', 'khi trước ', 'khiến ', 'khoảng ', 'khoảng cách ', 'khoảng không ', 'khá ', 'khá tốt ', 'khác ', 'khác gì ', 'khác khác ', 'khác nhau ', 'khác nào ', 'khác thường ', 'khác xa ', 'khách ', 'khó ', 'khó biết ', 'khó chơi ', 'khó khăn ', 'khó làm ', 'khó mở ', 'khó nghe ', 'khó nghĩ ', 'khó nói ', 'khó thấy ', 'khó tránh ', 'không ', 'không ai ', 'không bao giờ ', 'không bao lâu ', 'không biết ', 'không bán ', 'không chỉ ', 'không còn ', 'không có ', 'không có gì ', 'không cùng ', 'không cần ', 'không cứ ', 'không dùng ', 'không gì ', 'không hay ', 'không khỏi ', 'không kể ', 'không ngoài ', 'không nhận ', 'không những ', 'không phải ', 'không phải không ', 'không thể ', 'không tính ', 'không điều kiện ', 'không được ', 'không đầy ', 'không để ', 'khẳng định ', 'khỏi ', 'khỏi nói ', 'kể ', 'kể cả ', 'kể như ', 'kể tới ', 'kể từ ', 'liên quan ', 'loại ', 'loại từ ', 'luôn ', 'luôn cả ', 'luôn luôn ', 'luôn tay ', 'là ', 'là cùng ', 'là là ', 'là nhiều ', 'là phải ', 'là thế nào ', 'là vì ', 'là ít ', 'làm ', 'làm bằng ', 'làm cho ', 'làm dần dần ', 'làm gì ', 'làm lòng ', 'làm lại ', 'làm lấy ', 'làm mất ', 'làm ngay ', 'làm như ', 'làm nên ', 'làm ra ', 'làm riêng ', 'làm sao ', 'làm theo ', 'làm thế nào ', 'làm tin ', 'làm tôi ', 'làm tăng ', 'làm tại ', 'làm tắp lự ', 'làm vì ', 'làm đúng ', 'làm được ', 'lâu ', 'lâu các ', 'lâu lâu ', 'lâu nay ', 'lâu ngày ', 'lên ', 'lên cao ', 'lên cơn ', 'lên mạnh ', 'lên ngôi ', 'lên nước ', 'lên số ', 'lên xuống ', 'lên đến ', 'lòng ', 'lòng không ', 'lúc ', 'lúc khác ', 'lúc lâu ', 'lúc nào ', 'lúc này ', 'lúc sáng ', 'lúc trước ', 'lúc đi ', 'lúc đó ', 'lúc đến ', 'lúc ấy ', 'lý do ', 'lượng ', 'lượng cả ', 'lượng số ', 'lượng từ ', 'lại ', 'lại bộ ', 'lại cái ', 'lại còn ', 'lại giống ', 'lại làm ', 'lại người ', 'lại nói ', 'lại nữa ', 'lại quả ', 'lại thôi ', 'lại ăn ', 'lại đây ', 'lấy ', 'lấy có ', 'lấy cả ', 'lấy giống ', 'lấy làm ', 'lấy lý do ', 'lấy lại ', 'lấy ra ', 'lấy ráo ', 'lấy sau ', 'lấy số ', 'lấy thêm ', 'lấy thế ', 'lấy vào ', 'lấy xuống ', 'lấy được ', 'lấy để ', 'lần ', 'lần khác ', 'lần lần ', 'lần nào ', 'lần này ', 'lần sang ', 'lần sau ', 'lần theo ', 'lần trước ', 'lần tìm ', 'lớn ', 'lớn lên ', 'lớn nhỏ ', 'lời ', 'lời chú ', 'lời nói ', 'mang ', 'mang lại ', 'mang mang ', 'mang nặng ', 'mang về ', 'muốn ', 'mà ', 'mà cả ', 'mà không ', 'mà lại ', 'mà thôi ', 'mà vẫn ', 'mình ', 'mạnh ', 'mất ', 'mất còn ', 'mọi ', 'mọi giờ ', 'mọi khi ', 'mọi lúc ', 'mọi người ', 'mọi nơi ', 'mọi sự ', 'mọi thứ ', 'mọi việc ', 'mối ', 'mỗi ', 'mỗi lúc ', 'mỗi lần ', 'mỗi một ', 'mỗi ngày ', 'mỗi người ', 'một ', 'một cách ', 'một cơn ', 'một khi ', 'một lúc ', 'một số ', 'một vài ', 'một ít ', 'mới ', 'mới hay ', 'mới rồi ', 'mới đây ', 'mở ', 'mở mang ', 'mở nước ', 'mở ra ', 'mợ ', 'mức ', 'nay ', 'ngay ', 'ngay bây giờ ', 'ngay cả ', 'ngay khi ', 'ngay khi đến ', 'ngay lúc ', 'ngay lúc này ', 'ngay lập tức ', 'ngay thật ', 'ngay tức khắc ', 'ngay tức thì ', 'ngay từ ', 'nghe ', 'nghe chừng ', 'nghe hiểu ', 'nghe không ', 'nghe lại ', 'nghe nhìn ', 'nghe như ', 'nghe nói ', 'nghe ra ', 'nghe rõ ', 'nghe thấy ', 'nghe tin ', 'nghe trực tiếp ', 'nghe đâu ', 'nghe đâu như ', 'nghe được ', 'nghen ', 'nghiễm nhiên ', 'nghĩ ', 'nghĩ lại ', 'nghĩ ra ', 'nghĩ tới ', 'nghĩ xa ', 'nghĩ đến ', 'nghỉm ', 'ngoài ', 'ngoài này ', 'ngoài ra ', 'ngoài xa ', 'ngoải ', 'nguồn ', 'ngày ', 'ngày càng ', 'ngày cấp ', 'ngày giờ ', 'ngày ngày ', 'ngày nào ', 'ngày này ', 'ngày nọ ', 'ngày qua ', 'ngày rày ', 'ngày tháng ', 'ngày xưa ', 'ngày xửa ', 'ngày đến ', 'ngày ấy ', 'ngôi ', 'ngôi nhà ', 'ngôi thứ ', 'ngõ hầu ', 'ngăn ngắt ', 'ngươi ', 'người ', 'người hỏi ', 'người khác ', 'người khách ', 'người mình ', 'người nghe ', 'người người ', 'người nhận ', 'ngọn ', 'ngọn nguồn ', 'ngọt ', 'ngồi ', 'ngồi bệt ', 'ngồi không ', 'ngồi sau ', 'ngồi trệt ', 'ngộ nhỡ ', 'nhanh ', 'nhanh lên ', 'nhanh tay ', 'nhau ', 'nhiên hậu ', 'nhiều ', 'nhiều ít ', 'nhiệt liệt ', 'nhung nhăng ', 'nhà ', 'nhà chung ', 'nhà khó ', 'nhà làm ', 'nhà ngoài ', 'nhà ngươi ', 'nhà tôi ', 'nhà việc ', 'nhân dịp ', 'nhân tiện ', 'nhé ', 'nhìn ', 'nhìn chung ', 'nhìn lại ', 'nhìn nhận ', 'nhìn theo ', 'nhìn thấy ', 'nhìn xuống ', 'nhóm ', 'nhón nhén ', 'như ', 'như ai ', 'như chơi ', 'như không ', 'như là ', 'như nhau ', 'như quả ', 'như sau ', 'như thường ', 'như thế ', 'như thế nào ', 'như thể ', 'như trên ', 'như trước ', 'như tuồng ', 'như vậy ', 'như ý ', 'nhưng ', 'nhưng mà ', 'nhược bằng ', 'nhất ', 'nhất loạt ', 'nhất luật ', 'nhất là ', 'nhất mực ', 'nhất nhất ', 'nhất quyết ', 'nhất sinh ', 'nhất thiết ', 'nhất thì ', 'nhất tâm ', 'nhất tề ', 'nhất đán ', 'nhất định ', 'nhận ', 'nhận biết ', 'nhận họ ', 'nhận làm ', 'nhận nhau ', 'nhận ra ', 'nhận thấy ', 'nhận việc ', 'nhận được ', 'nhằm ', 'nhằm khi ', 'nhằm lúc ', 'nhằm vào ', 'nhằm để ', 'nhỉ ', 'nhỏ ', 'nhỏ người ', 'nhớ ', 'nhớ bập bõm ', 'nhớ lại ', 'nhớ lấy ', 'nhớ ra ', 'nhờ ', 'nhờ chuyển ', 'nhờ có ', 'nhờ nhờ ', 'nhờ đó ', 'nhỡ ra ', 'những ', 'những ai ', 'những khi ', 'những là ', 'những lúc ', 'những muốn ', 'những như ', 'nào ', 'nào cũng ', 'nào hay ', 'nào là ', 'nào phải ', 'nào đâu ', 'nào đó ', 'này ', 'này nọ ', 'nên ', 'nên chi ', 'nên chăng ', 'nên làm ', 'nên người ', 'nên tránh ', 'nó ', 'nóc ', 'nói ', 'nói bông ', 'nói chung ', 'nói khó ', 'nói là ', 'nói lên ', 'nói lại ', 'nói nhỏ ', 'nói phải ', 'nói qua ', 'nói ra ', 'nói riêng ', 'nói rõ ', 'nói thêm ', 'nói thật ', 'nói toẹt ', 'nói trước ', 'nói tốt ', 'nói với ', 'nói xa ', 'nói ý ', 'nói đến ', 'nói đủ ', 'năm ', 'năm tháng ', 'nơi ', 'nơi nơi ', 'nước ', 'nước bài ', 'nước cùng ', 'nước lên ', 'nước nặng ', 'nước quả ', 'nước xuống ', 'nước ăn ', 'nước đến ', 'nấy ', 'nặng ', 'nặng căn ', 'nặng mình ', 'nặng về ', 'nếu ', 'nếu có ', 'nếu cần ', 'nếu không ', 'nếu mà ', 'nếu như ', 'nếu thế ', 'nếu vậy ', 'nếu được ', 'nền ', 'nọ ', 'nớ ', 'nức nở ', 'nữa ', 'nữa khi ', 'nữa là ', 'nữa rồi ', 'oai oái ', 'oái ', 'pho ', 'phè ', 'phè phè ', 'phía ', 'phía bên ', 'phía bạn ', 'phía dưới ', 'phía sau ', 'phía trong ', 'phía trên ', 'phía trước ', 'phóc ', 'phót ', 'phù hợp ', 'phăn phắt ', 'phương chi ', 'phải ', 'phải biết ', 'phải chi ', 'phải chăng ', 'phải cách ', 'phải cái ', 'phải giờ ', 'phải khi ', 'phải không ', 'phải lại ', 'phải lời ', 'phải người ', 'phải như ', 'phải rồi ', 'phải tay ', 'phần ', 'phần lớn ', 'phần nhiều ', 'phần nào ', 'phần sau ', 'phần việc ', 'phắt ', 'phỉ phui ', 'phỏng ', 'phỏng như ', 'phỏng nước ', 'phỏng theo ', 'phỏng tính ', 'phốc ', 'phụt ', 'phứt ', 'qua ', 'qua chuyện ', 'qua khỏi ', 'qua lại ', 'qua lần ', 'qua ngày ', 'qua tay ', 'qua thì ', 'qua đi ', 'quan trọng ', 'quan trọng vấn đề ', 'quan tâm ', 'quay ', 'quay bước ', 'quay lại ', 'quay số ', 'quay đi ', 'quá ', 'quá bán ', 'quá bộ ', 'quá giờ ', 'quá lời ', 'quá mức ', 'quá nhiều ', 'quá tay ', 'quá thì ', 'quá tin ', 'quá trình ', 'quá tuổi ', 'quá đáng ', 'quá ư ', 'quả ', 'quả là ', 'quả thật ', 'quả thế ', 'quả vậy ', 'quận ', 'ra ', 'ra bài ', 'ra bộ ', 'ra chơi ', 'ra gì ', 'ra lại ', 'ra lời ', 'ra ngôi ', 'ra người ', 'ra sao ', 'ra tay ', 'ra vào ', 'ra ý ', 'ra điều ', 'ra đây ', 'ren rén ', 'riu ríu ', 'riêng ', 'riêng từng ', 'riệt ', 'rày ', 'ráo ', 'ráo cả ', 'ráo nước ', 'ráo trọi ', 'rén ', 'rén bước ', 'rích ', 'rón rén ', 'rõ ', 'rõ là ', 'rõ thật ', 'rút cục ', 'răng ', 'răng răng ', 'rất ', 'rất lâu ', 'rằng ', 'rằng là ', 'rốt cuộc ', 'rốt cục ', 'rồi ', 'rồi nữa ', 'rồi ra ', 'rồi sao ', 'rồi sau ', 'rồi tay ', 'rồi thì ', 'rồi xem ', 'rồi đây ', 'rứa ', 'sa sả ', 'sang ', 'sang năm ', 'sang sáng ', 'sang tay ', 'sao ', 'sao bản ', 'sao bằng ', 'sao cho ', 'sao vậy ', 'sao đang ', 'sau ', 'sau chót ', 'sau cuối ', 'sau cùng ', 'sau hết ', 'sau này ', 'sau nữa ', 'sau sau ', 'sau đây ', 'sau đó ', 'so ', 'so với ', 'song le ', 'suýt ', 'suýt nữa ', 'sáng ', 'sáng ngày ', 'sáng rõ ', 'sáng thế ', 'sáng ý ', 'sì ', 'sì sì ', 'sất ', 'sắp ', 'sắp đặt ', 'sẽ ', 'sẽ biết ', 'sẽ hay ', 'số ', 'số cho biết ', 'số cụ thể ', 'số loại ', 'số là ', 'số người ', 'số phần ', 'số thiếu ', 'sốt sột ', 'sớm ', 'sớm ngày ', 'sở dĩ ', 'sử dụng ', 'sự ', 'sự thế ', 'sự việc ', 'tanh ', 'tanh tanh ', 'tay ', 'tay quay ', 'tha hồ ', 'tha hồ chơi ', 'tha hồ ăn ', 'than ôi ', 'thanh ', 'thanh ba ', 'thanh chuyển ', 'thanh không ', 'thanh thanh ', 'thanh tính ', 'thanh điều kiện ', 'thanh điểm ', 'thay đổi ', 'thay đổi tình trạng ', 'theo ', 'theo bước ', 'theo như ', 'theo tin ', 'thi thoảng ', 'thiếu ', 'thiếu gì ', 'thiếu điểm ', 'thoạt ', 'thoạt nghe ', 'thoạt nhiên ', 'thoắt ', 'thuần ', 'thuần ái ', 'thuộc ', 'thuộc bài ', 'thuộc cách ', 'thuộc lại ', 'thuộc từ ', 'thà ', 'thà là ', 'thà rằng ', 'thành ra ', 'thành thử ', 'thái quá ', 'tháng ', 'tháng ngày ', 'tháng năm ', 'tháng tháng ', 'thêm ', 'thêm chuyện ', 'thêm giờ ', 'thêm vào ', 'thì ', 'thì giờ ', 'thì là ', 'thì phải ', 'thì ra ', 'thì thôi ', 'thình lình ', 'thích ', 'thích cứ ', 'thích thuộc ', 'thích tự ', 'thích ý ', 'thím ', 'thôi ', 'thôi việc ', 'thúng thắng ', 'thương ôi ', 'thường ', 'thường bị ', 'thường hay ', 'thường khi ', 'thường số ', 'thường sự ', 'thường thôi ', 'thường thường ', 'thường tính ', 'thường tại ', 'thường xuất hiện ', 'thường đến ', 'thảo hèn ', 'thảo nào ', 'thấp ', 'thấp cơ ', 'thấp thỏm ', 'thấp xuống ', 'thấy ', 'thấy tháng ', 'thẩy ', 'thậm ', 'thậm chí ', 'thậm cấp ', 'thậm từ ', 'thật ', 'thật chắc ', 'thật là ', 'thật lực ', 'thật quả ', 'thật ra ', 'thật sự ', 'thật thà ', 'thật tốt ', 'thật vậy ', 'thế ', 'thế chuẩn bị ', 'thế là ', 'thế lại ', 'thế mà ', 'thế nào ', 'thế nên ', 'thế ra ', 'thế sự ', 'thế thì ', 'thế thôi ', 'thế thường ', 'thế thế ', 'thế à ', 'thế đó ', 'thếch ', 'thỉnh thoảng ', 'thỏm ', 'thốc ', 'thốc tháo ', 'thốt ', 'thốt nhiên ', 'thốt nói ', 'thốt thôi ', 'thộc ', 'thời gian ', 'thời gian sử dụng ', 'thời gian tính ', 'thời điểm ', 'thục mạng ', 'thứ ', 'thứ bản ', 'thứ đến ', 'thửa ', 'thực hiện ', 'thực hiện đúng ', 'thực ra ', 'thực sự ', 'thực tế ', 'thực vậy ', 'tin ', 'tin thêm ', 'tin vào ', 'tiếp theo ', 'tiếp tục ', 'tiếp đó ', 'tiện thể ', 'toà ', 'toé khói ', 'toẹt ', 'trong ', 'trong khi ', 'trong lúc ', 'trong mình ', 'trong ngoài ', 'trong này ', 'trong số ', 'trong vùng ', 'trong đó ', 'trong ấy ', 'tránh ', 'tránh khỏi ', 'tránh ra ', 'tránh tình trạng ', 'tránh xa ', 'trên ', 'trên bộ ', 'trên dưới ', 'trước ', 'trước hết ', 'trước khi ', 'trước kia ', 'trước nay ', 'trước ngày ', 'trước nhất ', 'trước sau ', 'trước tiên ', 'trước tuổi ', 'trước đây ', 'trước đó ', 'trả ', 'trả của ', 'trả lại ', 'trả ngay ', 'trả trước ', 'trếu tráo ', 'trển ', 'trệt ', 'trệu trạo ', 'trỏng ', 'trời đất ơi ', 'trở thành ', 'trừ phi ', 'trực tiếp ', 'trực tiếp làm ', 'tuy ', 'tuy có ', 'tuy là ', 'tuy nhiên ', 'tuy rằng ', 'tuy thế ', 'tuy vậy ', 'tuy đã ', 'tuyệt nhiên ', 'tuần tự ', 'tuốt luốt ', 'tuốt tuồn tuột ', 'tuốt tuột ', 'tuổi ', 'tuổi cả ', 'tuổi tôi ', 'tà tà ', 'tên ', 'tên chính ', 'tên cái ', 'tên họ ', 'tên tự ', 'tênh ', 'tênh tênh ', 'tìm ', 'tìm bạn ', 'tìm cách ', 'tìm hiểu ', 'tìm ra ', 'tìm việc ', 'tình trạng ', 'tính ', 'tính cách ', 'tính căn ', 'tính người ', 'tính phỏng ', 'tính từ ', 'tít mù ', 'tò te ', 'tôi ', 'tôi con ', 'tông tốc ', 'tù tì ', 'tăm tắp ', 'tăng ', 'tăng chúng ', 'tăng cấp ', 'tăng giảm ', 'tăng thêm ', 'tăng thế ', 'tại ', 'tại lòng ', 'tại nơi ', 'tại sao ', 'tại tôi ', 'tại vì ', 'tại đâu ', 'tại đây ', 'tại đó ', 'tạo ', 'tạo cơ hội ', 'tạo nên ', 'tạo ra ', 'tạo ý ', 'tạo điều kiện ', 'tấm ', 'tấm bản ', 'tấm các ', 'tấn ', 'tấn tới ', 'tất cả ', 'tất cả bao nhiêu ', 'tất thảy ', 'tất tần tật ', 'tất tật ', 'tập trung ', 'tắp ', 'tắp lự ', 'tắp tắp ', 'tọt ', 'tỏ ra ', 'tỏ vẻ ', 'tốc tả ', 'tối ư ', 'tốt ', 'tốt bạn ', 'tốt bộ ', 'tốt hơn ', 'tốt mối ', 'tốt ngày ', 'tột ', 'tột cùng ', 'tớ ', 'tới ', 'tới gần ', 'tới mức ', 'tới nơi ', 'tới thì ', 'tức thì ', 'tức tốc ', 'từ ', 'từ căn ', 'từ giờ ', 'từ khi ', 'từ loại ', 'từ nay ', 'từ thế ', 'từ tính ', 'từ tại ', 'từ từ ', 'từ ái ', 'từ điều ', 'từ đó ', 'từ ấy ', 'từng ', 'từng cái ', 'từng giờ ', 'từng nhà ', 'từng phần ', 'từng thời gian ', 'từng đơn vị ', 'từng ấy ', 'tự ', 'tự cao ', 'tự khi ', 'tự lượng ', 'tự tính ', 'tự tạo ', 'tự vì ', 'tự ý ', 'tự ăn ', 'tựu trung ', 'veo ', 'veo veo ', 'việc ', 'việc gì ', 'vung thiên địa ', 'vung tàn tán ', 'vung tán tàn ', 'và ', 'vài ', 'vài ba ', 'vài người ', 'vài nhà ', 'vài nơi ', 'vài tên ', 'vài điều ', 'vào ', 'vào gặp ', 'vào khoảng ', 'vào lúc ', 'vào vùng ', 'vào đến ', 'vâng ', 'vâng chịu ', 'vâng dạ ', 'vâng vâng ', 'vâng ý ', 'vèo ', 'vèo vèo ', 'vì ', 'vì chưng ', 'vì rằng ', 'vì sao ', 'vì thế ', 'vì vậy ', 'ví bằng ', 'ví dù ', 'ví phỏng ', 'ví thử ', 'vô hình trung ', 'vô kể ', 'vô luận ', 'vô vàn ', 'vùng ', 'vùng lên ', 'vùng nước ', 'văng tê ', 'vượt ', 'vượt khỏi ', 'vượt quá ', 'vạn nhất ', 'vả chăng ', 'vả lại ', 'vấn đề ', 'vấn đề quan trọng ', 'vẫn ', 'vẫn thế ', 'vậy ', 'vậy là ', 'vậy mà ', 'vậy nên ', 'vậy ra ', 'vậy thì ', 'vậy ư ', 'về ', 'về không ', 'về nước ', 'về phần ', 'về sau ', 'về tay ', 'vị trí ', 'vị tất ', 'vốn dĩ ', 'với ', 'với lại ', 'với nhau ', 'vở ', 'vụt ', 'vừa ', 'vừa khi ', 'vừa lúc ', 'vừa mới ', 'vừa qua ', 'vừa rồi ', 'vừa vừa ', 'xa ', 'xa cách ', 'xa gần ', 'xa nhà ', 'xa tanh ', 'xa tắp ', 'xa xa ', 'xa xả ', 'xem ', 'xem lại ', 'xem ra ', 'xem số ', 'xin ', 'xin gặp ', 'xin vâng ', 'xiết bao ', 'xon xón ', 'xoành xoạch ', 'xoét ', 'xoẳn ', 'xoẹt ', 'xuất hiện ', 'xuất kì bất ý ', 'xuất kỳ bất ý ', 'xuể ', 'xuống ', 'xăm xúi ', 'xăm xăm ', 'xăm xắm ', 'xảy ra ', 'xềnh xệch ', 'xệp ', 'xử lý ', 'yêu cầu ', 'à ', 'à này ', 'à ơi ', 'ào ', 'ào vào ', 'ào ào ', 'á ', 'á à ', 'ái ', 'ái chà ', 'ái dà ', 'áng ', 'áng như ', 'âu là ', 'ít ', 'ít biết ', 'ít có ', 'ít hơn ', 'ít khi ', 'ít lâu ', 'ít nhiều ', 'ít nhất ', 'ít nữa ', 'ít quá ', 'ít ra ', 'ít thôi ', 'ít thấy ', 'ô hay ', 'ô hô ', 'ô kê ', 'ô kìa ', 'ôi chao ', 'ôi thôi ', 'ông ', 'ông nhỏ ', 'ông tạo ', 'ông từ ', 'ông ấy ', 'ông ổng ', 'úi ', 'úi chà ', 'úi dào ', 'ý ', 'ý chừng ', 'ý da ', 'ý hoặc ', 'ăn ', 'ăn chung ', 'ăn chắc ', 'ăn chịu ', 'ăn cuộc ', 'ăn hết ', 'ăn hỏi ', 'ăn làm ', 'ăn người ', 'ăn ngồi ', 'ăn quá ', 'ăn riêng ', 'ăn sáng ', 'ăn tay ', 'ăn trên ', 'ăn về ', 'đang ', 'đang tay ', 'đang thì ', 'điều ', 'điều gì ', 'điều kiện ', 'điểm ', 'điểm chính ', 'điểm gặp ', 'điểm đầu tiên ', 'đành đạch ', 'đáng ', 'đáng kể ', 'đáng lí ', 'đáng lý ', 'đáng lẽ ', 'đáng số ', 'đánh giá ', 'đánh đùng ', 'đáo để ', 'đâu ', 'đâu có ', 'đâu cũng ', 'đâu như ', 'đâu nào ', 'đâu phải ', 'đâu đâu ', 'đâu đây ', 'đâu đó ', 'đây ', 'đây này ', 'đây rồi ', 'đây đó ', 'đã ', 'đã hay ', 'đã không ', 'đã là ', 'đã lâu ', 'đã thế ', 'đã vậy ', 'đã đủ ', 'đó ', 'đó đây ', 'đúng ', 'đúng ngày ', 'đúng ra ', 'đúng tuổi ', 'đúng với ', 'đơn vị ', 'đưa ', 'đưa cho ', 'đưa chuyện ', 'đưa em ', 'đưa ra ', 'đưa tay ', 'đưa tin ', 'đưa tới ', 'đưa vào ', 'đưa về ', 'đưa xuống ', 'đưa đến ', 'được ', 'được cái ', 'được lời ', 'được nước ', 'được tin ', 'đại loại ', 'đại nhân ', 'đại phàm ', 'đại để ', 'đạt ', 'đảm bảo ', 'đầu tiên ', 'đầy ', 'đầy năm ', 'đầy phè ', 'đầy tuổi ', 'đặc biệt ', 'đặt ', 'đặt làm ', 'đặt mình ', 'đặt mức ', 'đặt ra ', 'đặt trước ', 'đặt để ', 'đến ', 'đến bao giờ ', 'đến cùng ', 'đến cùng cực ', 'đến cả ', 'đến giờ ', 'đến gần ', 'đến hay ', 'đến khi ', 'đến lúc ', 'đến lời ', 'đến nay ', 'đến ngày ', 'đến nơi ', 'đến nỗi ', 'đến thì ', 'đến thế ', 'đến tuổi ', 'đến xem ', 'đến điều ', 'đến đâu ', 'đều ', 'đều bước ', 'đều nhau ', 'đều đều ', 'để ', 'để cho ', 'để giống ', 'để không ', 'để lòng ', 'để lại ', 'để mà ', 'để phần ', 'để được ', 'để đến nỗi ', 'đối với ', 'đồng thời ', 'đủ ', 'đủ dùng ', 'đủ nơi ', 'đủ số ', 'đủ điều ', 'đủ điểm ', 'ơ ', 'ơ hay ', 'ơ kìa ', 'ơi ', 'ơi là ', 'ư ', 'ạ ', 'ạ ơi ', 'ấy ', 'ấy là ', 'ầu ơ ', 'ắt ', 'ắt hẳn ', 'ắt là ', 'ắt phải ', 'ắt thật ', 'ối dào ', 'ối giời ', 'ối giời ơi ', 'ồ ', 'ồ ồ ', 'ổng ', 'ớ ', 'ớ này ', 'ờ ', 'ờ ờ ', 'ở ', 'ở lại ', 'ở như ', 'ở nhờ ', 'ở năm ', 'ở trên ', 'ở vào ', 'ở đây ', 'ở đó ', 'ở được ', 'ủa ', 'ứ hự ', 'ứ ừ ', 'ừ ', 'ừ nhé ', 'ừ thì ', 'ừ ào ', 'ừ ừ ', 'ử']}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 3), (1, 5)],\n",
        "    'tfidf__stop_words': [STOPWORDS, None],\n",
        "    'tfidf__max_df': [0.5, 0.75, 1.0],\n",
        "    'tfidf__min_df': [2, 3, 4],\n",
        "    'tfidf__smooth_idf': [True, False],\n",
        "}\n",
        "\n",
        "# Define the pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('ovr', OneVsRestClassifier(LogisticRegression(random_state = 42)))\n",
        "])\n",
        "\n",
        "# Initialize the grid search\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Print the best parameters\n",
        "print(best_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF4RIeDeLpYY",
        "outputId": "319f5323-a700-46b7-ea45-0d5e67ebb9a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'bow__max_df': 0.75, 'bow__min_df': 2, 'bow__ngram_range': (1, 3), 'bow__stop_words': ['a lô ', 'a ha ', 'ai ', 'ai ai ', 'ai nấy ', 'ai đó ', 'alô ', 'amen ', 'anh ', 'anh ấy ', 'ba ', 'ba ba ', 'ba bản ', 'ba cùng ', 'ba họ ', 'ba ngày ', 'ba ngôi ', 'ba tăng ', 'bao giờ ', 'bao lâu ', 'bao nhiêu ', 'bao nả ', 'bay biến ', 'biết ', 'biết bao ', 'biết bao nhiêu ', 'biết chắc ', 'biết chừng nào ', 'biết mình ', 'biết mấy ', 'biết thế ', 'biết trước ', 'biết việc ', 'biết đâu ', 'biết đâu chừng ', 'biết đâu đấy ', 'biết được ', 'buổi ', 'buổi làm ', 'buổi mới ', 'buổi ngày ', 'buổi sớm ', 'bà ', 'bà ấy ', 'bài ', 'bài bác ', 'bài bỏ ', 'bài cái ', 'bác ', 'bán ', 'bán cấp ', 'bán dạ ', 'bán thế ', 'bây bẩy ', 'bây chừ ', 'bây giờ ', 'bây nhiêu ', 'bèn ', 'béng ', 'bên ', 'bên bị ', 'bên có ', 'bên cạnh ', 'bông ', 'bước ', 'bước khỏi ', 'bước tới ', 'bước đi ', 'bạn ', 'bản ', 'bản bộ ', 'bản riêng ', 'bản thân ', 'bản ý ', 'bất chợt ', 'bất cứ ', 'bất giác ', 'bất kì ', 'bất kể ', 'bất kỳ ', 'bất luận ', 'bất ngờ ', 'bất nhược ', 'bất quá ', 'bất quá chỉ ', 'bất thình lình ', 'bất tử ', 'bất đồ ', 'bấy ', 'bấy chầy ', 'bấy chừ ', 'bấy giờ ', 'bấy lâu ', 'bấy lâu nay ', 'bấy nay ', 'bấy nhiêu ', 'bập bà bập bõm ', 'bập bõm ', 'bắt đầu ', 'bắt đầu từ ', 'bằng ', 'bằng cứ ', 'bằng không ', 'bằng người ', 'bằng nhau ', 'bằng như ', 'bằng nào ', 'bằng nấy ', 'bằng vào ', 'bằng được ', 'bằng ấy ', 'bển ', 'bệt ', 'bị ', 'bị chú ', 'bị vì ', 'bỏ ', 'bỏ bà ', 'bỏ cha ', 'bỏ cuộc ', 'bỏ không ', 'bỏ lại ', 'bỏ mình ', 'bỏ mất ', 'bỏ mẹ ', 'bỏ nhỏ ', 'bỏ quá ', 'bỏ ra ', 'bỏ riêng ', 'bỏ việc ', 'bỏ xa ', 'bỗng ', 'bỗng chốc ', 'bỗng dưng ', 'bỗng không ', 'bỗng nhiên ', 'bỗng nhưng ', 'bỗng thấy ', 'bỗng đâu ', 'bộ ', 'bộ thuộc ', 'bộ điều ', 'bội phần ', 'bớ ', 'bởi ', 'bởi ai ', 'bởi chưng ', 'bởi nhưng ', 'bởi sao ', 'bởi thế ', 'bởi thế cho nên ', 'bởi tại ', 'bởi vì ', 'bởi vậy ', 'bởi đâu ', 'bức ', 'cao ', 'cao lâu ', 'cao ráo ', 'cao răng ', 'cao sang ', 'cao số ', 'cao thấp ', 'cao thế ', 'cao xa ', 'cha ', 'cha chả ', 'chao ôi ', 'chia sẻ ', 'chiếc ', 'cho ', 'cho biết ', 'cho chắc ', 'cho hay ', 'cho nhau ', 'cho nên ', 'cho rằng ', 'cho rồi ', 'cho thấy ', 'cho tin ', 'cho tới ', 'cho tới khi ', 'cho về ', 'cho ăn ', 'cho đang ', 'cho được ', 'cho đến ', 'cho đến khi ', 'cho đến nỗi ', 'choa ', 'chu cha ', 'chui cha ', 'chung ', 'chung cho ', 'chung chung ', 'chung cuộc ', 'chung cục ', 'chung nhau ', 'chung qui ', 'chung quy ', 'chung quy lại ', 'chung ái ', 'chuyển ', 'chuyển tự ', 'chuyển đạt ', 'chuyện ', 'chuẩn bị ', 'chành chạnh ', 'chí chết ', 'chính ', 'chính bản ', 'chính giữa ', 'chính là ', 'chính thị ', 'chính điểm ', 'chùn chùn ', 'chùn chũn ', 'chú ', 'chú dẫn ', 'chú khách ', 'chú mày ', 'chú mình ', 'chúng ', 'chúng mình ', 'chúng ta ', 'chúng tôi ', 'chúng ông ', 'chăn chắn ', 'chăng ', 'chăng chắc ', 'chăng nữa ', 'chơi ', 'chơi họ ', 'chưa ', 'chưa bao giờ ', 'chưa chắc ', 'chưa có ', 'chưa cần ', 'chưa dùng ', 'chưa dễ ', 'chưa kể ', 'chưa tính ', 'chưa từng ', 'chầm chập ', 'chậc ', 'chắc ', 'chắc chắn ', 'chắc dạ ', 'chắc hẳn ', 'chắc lòng ', 'chắc người ', 'chắc vào ', 'chắc ăn ', 'chẳng lẽ ', 'chẳng những ', 'chẳng nữa ', 'chẳng phải ', 'chết nỗi ', 'chết thật ', 'chết tiệt ', 'chỉ ', 'chỉ chính ', 'chỉ có ', 'chỉ là ', 'chỉ tên ', 'chỉn ', 'chị ', 'chị bộ ', 'chị ấy ', 'chịu ', 'chịu chưa ', 'chịu lời ', 'chịu tốt ', 'chịu ăn ', 'chọn ', 'chọn bên ', 'chọn ra ', 'chốc chốc ', 'chớ ', 'chớ chi ', 'chớ gì ', 'chớ không ', 'chớ kể ', 'chớ như ', 'chợt ', 'chợt nghe ', 'chợt nhìn ', 'chủn ', 'chứ ', 'chứ ai ', 'chứ còn ', 'chứ gì ', 'chứ không ', 'chứ không phải ', 'chứ lại ', 'chứ lị ', 'chứ như ', 'chứ sao ', 'coi bộ ', 'coi mòi ', 'con ', 'con con ', 'con dạ ', 'con nhà ', 'con tính ', 'cu cậu ', 'cuối ', 'cuối cùng ', 'cuối điểm ', 'cuốn ', 'cuộc ', 'càng ', 'càng càng ', 'càng hay ', 'cá nhân ', 'các ', 'các cậu ', 'cách ', 'cách bức ', 'cách không ', 'cách nhau ', 'cách đều ', 'cái ', 'cái gì ', 'cái họ ', 'cái đã ', 'cái đó ', 'cái ấy ', 'câu hỏi ', 'cây ', 'cây nước ', 'còn ', 'còn như ', 'còn nữa ', 'còn thời gian ', 'còn về ', 'có ', 'có ai ', 'có chuyện ', 'có chăng ', 'có chăng là ', 'có chứ ', 'có cơ ', 'có dễ ', 'có họ ', 'có khi ', 'có ngày ', 'có người ', 'có nhiều ', 'có nhà ', 'có phải ', 'có số ', 'có tháng ', 'có thế ', 'có thể ', 'có vẻ ', 'có ý ', 'có ăn ', 'có điều ', 'có điều kiện ', 'có đáng ', 'có đâu ', 'có được ', 'cóc khô ', 'cô ', 'cô mình ', 'cô quả ', 'cô tăng ', 'cô ấy ', 'công nhiên ', 'cùng ', 'cùng chung ', 'cùng cực ', 'cùng nhau ', 'cùng tuổi ', 'cùng tột ', 'cùng với ', 'cùng ăn ', 'căn ', 'căn cái ', 'căn cắt ', 'căn tính ', 'cũng ', 'cũng như ', 'cũng nên ', 'cũng thế ', 'cũng vậy ', 'cũng vậy thôi ', 'cũng được ', 'cơ ', 'cơ chỉ ', 'cơ chừng ', 'cơ cùng ', 'cơ dẫn ', 'cơ hồ ', 'cơ hội ', 'cơ mà ', 'cơn ', 'cả ', 'cả nghe ', 'cả nghĩ ', 'cả ngày ', 'cả người ', 'cả nhà ', 'cả năm ', 'cả thảy ', 'cả thể ', 'cả tin ', 'cả ăn ', 'cả đến ', 'cảm thấy ', 'cảm ơn ', 'cấp ', 'cấp số ', 'cấp trực tiếp ', 'cần ', 'cần cấp ', 'cần gì ', 'cần số ', 'cật lực ', 'cật sức ', 'cậu ', 'cổ lai ', 'cụ thể ', 'cụ thể là ', 'cụ thể như ', 'của ', 'của ngọt ', 'của tin ', 'cứ ', 'cứ như ', 'cứ việc ', 'cứ điểm ', 'cực lực ', 'do ', 'do vì ', 'do vậy ', 'do đó ', 'duy ', 'duy chỉ ', 'duy có ', 'dài ', 'dài lời ', 'dài ra ', 'dành ', 'dành dành ', 'dào ', 'dì ', 'dù ', 'dù cho ', 'dù dì ', 'dù gì ', 'dù rằng ', 'dù sao ', 'dùng ', 'dùng cho ', 'dùng hết ', 'dùng làm ', 'dùng đến ', 'dưới ', 'dưới nước ', 'dạ ', 'dạ bán ', 'dạ con ', 'dạ dài ', 'dạ dạ ', 'dạ khách ', 'dần dà ', 'dần dần ', 'dầu sao ', 'dẫn ', 'dẫu ', 'dẫu mà ', 'dẫu rằng ', 'dẫu sao ', 'dễ ', 'dễ dùng ', 'dễ gì ', 'dễ khiến ', 'dễ nghe ', 'dễ ngươi ', 'dễ như chơi ', 'dễ sợ ', 'dễ sử dụng ', 'dễ thường ', 'dễ thấy ', 'dễ ăn ', 'dễ đâu ', 'dở chừng ', 'dữ ', 'dữ cách ', 'em ', 'em em ', 'giá trị ', 'giá trị thực tế ', 'giảm ', 'giảm chính ', 'giảm thấp ', 'giảm thế ', 'giống ', 'giống người ', 'giống nhau ', 'giống như ', 'giờ ', 'giờ lâu ', 'giờ này ', 'giờ đi ', 'giờ đây ', 'giờ đến ', 'giữ ', 'giữ lấy ', 'giữ ý ', 'giữa ', 'giữa lúc ', 'gây ', 'gây cho ', 'gây giống ', 'gây ra ', 'gây thêm ', 'gì ', 'gì gì ', 'gì đó ', 'gần ', 'gần bên ', 'gần hết ', 'gần ngày ', 'gần như ', 'gần xa ', 'gần đây ', 'gần đến ', 'gặp ', 'gặp khó khăn ', 'gặp phải ', 'gồm ', 'hay ', 'hay biết ', 'hay hay ', 'hay không ', 'hay là ', 'hay làm ', 'hay nhỉ ', 'hay nói ', 'hay sao ', 'hay tin ', 'hay đâu ', 'hiểu ', 'hiện nay ', 'hiện tại ', 'hoàn toàn ', 'hoặc ', 'hoặc là ', 'hãy ', 'hãy còn ', 'hơn ', 'hơn cả ', 'hơn hết ', 'hơn là ', 'hơn nữa ', 'hơn trước ', 'hầu hết ', 'hết ', 'hết chuyện ', 'hết cả ', 'hết của ', 'hết nói ', 'hết ráo ', 'hết rồi ', 'hết ý ', 'họ ', 'họ gần ', 'họ xa ', 'hỏi ', 'hỏi lại ', 'hỏi xem ', 'hỏi xin ', 'hỗ trợ ', 'khi ', 'khi khác ', 'khi không ', 'khi nào ', 'khi nên ', 'khi trước ', 'khiến ', 'khoảng ', 'khoảng cách ', 'khoảng không ', 'khá ', 'khá tốt ', 'khác ', 'khác gì ', 'khác khác ', 'khác nhau ', 'khác nào ', 'khác thường ', 'khác xa ', 'khách ', 'khó ', 'khó biết ', 'khó chơi ', 'khó khăn ', 'khó làm ', 'khó mở ', 'khó nghe ', 'khó nghĩ ', 'khó nói ', 'khó thấy ', 'khó tránh ', 'không ', 'không ai ', 'không bao giờ ', 'không bao lâu ', 'không biết ', 'không bán ', 'không chỉ ', 'không còn ', 'không có ', 'không có gì ', 'không cùng ', 'không cần ', 'không cứ ', 'không dùng ', 'không gì ', 'không hay ', 'không khỏi ', 'không kể ', 'không ngoài ', 'không nhận ', 'không những ', 'không phải ', 'không phải không ', 'không thể ', 'không tính ', 'không điều kiện ', 'không được ', 'không đầy ', 'không để ', 'khẳng định ', 'khỏi ', 'khỏi nói ', 'kể ', 'kể cả ', 'kể như ', 'kể tới ', 'kể từ ', 'liên quan ', 'loại ', 'loại từ ', 'luôn ', 'luôn cả ', 'luôn luôn ', 'luôn tay ', 'là ', 'là cùng ', 'là là ', 'là nhiều ', 'là phải ', 'là thế nào ', 'là vì ', 'là ít ', 'làm ', 'làm bằng ', 'làm cho ', 'làm dần dần ', 'làm gì ', 'làm lòng ', 'làm lại ', 'làm lấy ', 'làm mất ', 'làm ngay ', 'làm như ', 'làm nên ', 'làm ra ', 'làm riêng ', 'làm sao ', 'làm theo ', 'làm thế nào ', 'làm tin ', 'làm tôi ', 'làm tăng ', 'làm tại ', 'làm tắp lự ', 'làm vì ', 'làm đúng ', 'làm được ', 'lâu ', 'lâu các ', 'lâu lâu ', 'lâu nay ', 'lâu ngày ', 'lên ', 'lên cao ', 'lên cơn ', 'lên mạnh ', 'lên ngôi ', 'lên nước ', 'lên số ', 'lên xuống ', 'lên đến ', 'lòng ', 'lòng không ', 'lúc ', 'lúc khác ', 'lúc lâu ', 'lúc nào ', 'lúc này ', 'lúc sáng ', 'lúc trước ', 'lúc đi ', 'lúc đó ', 'lúc đến ', 'lúc ấy ', 'lý do ', 'lượng ', 'lượng cả ', 'lượng số ', 'lượng từ ', 'lại ', 'lại bộ ', 'lại cái ', 'lại còn ', 'lại giống ', 'lại làm ', 'lại người ', 'lại nói ', 'lại nữa ', 'lại quả ', 'lại thôi ', 'lại ăn ', 'lại đây ', 'lấy ', 'lấy có ', 'lấy cả ', 'lấy giống ', 'lấy làm ', 'lấy lý do ', 'lấy lại ', 'lấy ra ', 'lấy ráo ', 'lấy sau ', 'lấy số ', 'lấy thêm ', 'lấy thế ', 'lấy vào ', 'lấy xuống ', 'lấy được ', 'lấy để ', 'lần ', 'lần khác ', 'lần lần ', 'lần nào ', 'lần này ', 'lần sang ', 'lần sau ', 'lần theo ', 'lần trước ', 'lần tìm ', 'lớn ', 'lớn lên ', 'lớn nhỏ ', 'lời ', 'lời chú ', 'lời nói ', 'mang ', 'mang lại ', 'mang mang ', 'mang nặng ', 'mang về ', 'muốn ', 'mà ', 'mà cả ', 'mà không ', 'mà lại ', 'mà thôi ', 'mà vẫn ', 'mình ', 'mạnh ', 'mất ', 'mất còn ', 'mọi ', 'mọi giờ ', 'mọi khi ', 'mọi lúc ', 'mọi người ', 'mọi nơi ', 'mọi sự ', 'mọi thứ ', 'mọi việc ', 'mối ', 'mỗi ', 'mỗi lúc ', 'mỗi lần ', 'mỗi một ', 'mỗi ngày ', 'mỗi người ', 'một ', 'một cách ', 'một cơn ', 'một khi ', 'một lúc ', 'một số ', 'một vài ', 'một ít ', 'mới ', 'mới hay ', 'mới rồi ', 'mới đây ', 'mở ', 'mở mang ', 'mở nước ', 'mở ra ', 'mợ ', 'mức ', 'nay ', 'ngay ', 'ngay bây giờ ', 'ngay cả ', 'ngay khi ', 'ngay khi đến ', 'ngay lúc ', 'ngay lúc này ', 'ngay lập tức ', 'ngay thật ', 'ngay tức khắc ', 'ngay tức thì ', 'ngay từ ', 'nghe ', 'nghe chừng ', 'nghe hiểu ', 'nghe không ', 'nghe lại ', 'nghe nhìn ', 'nghe như ', 'nghe nói ', 'nghe ra ', 'nghe rõ ', 'nghe thấy ', 'nghe tin ', 'nghe trực tiếp ', 'nghe đâu ', 'nghe đâu như ', 'nghe được ', 'nghen ', 'nghiễm nhiên ', 'nghĩ ', 'nghĩ lại ', 'nghĩ ra ', 'nghĩ tới ', 'nghĩ xa ', 'nghĩ đến ', 'nghỉm ', 'ngoài ', 'ngoài này ', 'ngoài ra ', 'ngoài xa ', 'ngoải ', 'nguồn ', 'ngày ', 'ngày càng ', 'ngày cấp ', 'ngày giờ ', 'ngày ngày ', 'ngày nào ', 'ngày này ', 'ngày nọ ', 'ngày qua ', 'ngày rày ', 'ngày tháng ', 'ngày xưa ', 'ngày xửa ', 'ngày đến ', 'ngày ấy ', 'ngôi ', 'ngôi nhà ', 'ngôi thứ ', 'ngõ hầu ', 'ngăn ngắt ', 'ngươi ', 'người ', 'người hỏi ', 'người khác ', 'người khách ', 'người mình ', 'người nghe ', 'người người ', 'người nhận ', 'ngọn ', 'ngọn nguồn ', 'ngọt ', 'ngồi ', 'ngồi bệt ', 'ngồi không ', 'ngồi sau ', 'ngồi trệt ', 'ngộ nhỡ ', 'nhanh ', 'nhanh lên ', 'nhanh tay ', 'nhau ', 'nhiên hậu ', 'nhiều ', 'nhiều ít ', 'nhiệt liệt ', 'nhung nhăng ', 'nhà ', 'nhà chung ', 'nhà khó ', 'nhà làm ', 'nhà ngoài ', 'nhà ngươi ', 'nhà tôi ', 'nhà việc ', 'nhân dịp ', 'nhân tiện ', 'nhé ', 'nhìn ', 'nhìn chung ', 'nhìn lại ', 'nhìn nhận ', 'nhìn theo ', 'nhìn thấy ', 'nhìn xuống ', 'nhóm ', 'nhón nhén ', 'như ', 'như ai ', 'như chơi ', 'như không ', 'như là ', 'như nhau ', 'như quả ', 'như sau ', 'như thường ', 'như thế ', 'như thế nào ', 'như thể ', 'như trên ', 'như trước ', 'như tuồng ', 'như vậy ', 'như ý ', 'nhưng ', 'nhưng mà ', 'nhược bằng ', 'nhất ', 'nhất loạt ', 'nhất luật ', 'nhất là ', 'nhất mực ', 'nhất nhất ', 'nhất quyết ', 'nhất sinh ', 'nhất thiết ', 'nhất thì ', 'nhất tâm ', 'nhất tề ', 'nhất đán ', 'nhất định ', 'nhận ', 'nhận biết ', 'nhận họ ', 'nhận làm ', 'nhận nhau ', 'nhận ra ', 'nhận thấy ', 'nhận việc ', 'nhận được ', 'nhằm ', 'nhằm khi ', 'nhằm lúc ', 'nhằm vào ', 'nhằm để ', 'nhỉ ', 'nhỏ ', 'nhỏ người ', 'nhớ ', 'nhớ bập bõm ', 'nhớ lại ', 'nhớ lấy ', 'nhớ ra ', 'nhờ ', 'nhờ chuyển ', 'nhờ có ', 'nhờ nhờ ', 'nhờ đó ', 'nhỡ ra ', 'những ', 'những ai ', 'những khi ', 'những là ', 'những lúc ', 'những muốn ', 'những như ', 'nào ', 'nào cũng ', 'nào hay ', 'nào là ', 'nào phải ', 'nào đâu ', 'nào đó ', 'này ', 'này nọ ', 'nên ', 'nên chi ', 'nên chăng ', 'nên làm ', 'nên người ', 'nên tránh ', 'nó ', 'nóc ', 'nói ', 'nói bông ', 'nói chung ', 'nói khó ', 'nói là ', 'nói lên ', 'nói lại ', 'nói nhỏ ', 'nói phải ', 'nói qua ', 'nói ra ', 'nói riêng ', 'nói rõ ', 'nói thêm ', 'nói thật ', 'nói toẹt ', 'nói trước ', 'nói tốt ', 'nói với ', 'nói xa ', 'nói ý ', 'nói đến ', 'nói đủ ', 'năm ', 'năm tháng ', 'nơi ', 'nơi nơi ', 'nước ', 'nước bài ', 'nước cùng ', 'nước lên ', 'nước nặng ', 'nước quả ', 'nước xuống ', 'nước ăn ', 'nước đến ', 'nấy ', 'nặng ', 'nặng căn ', 'nặng mình ', 'nặng về ', 'nếu ', 'nếu có ', 'nếu cần ', 'nếu không ', 'nếu mà ', 'nếu như ', 'nếu thế ', 'nếu vậy ', 'nếu được ', 'nền ', 'nọ ', 'nớ ', 'nức nở ', 'nữa ', 'nữa khi ', 'nữa là ', 'nữa rồi ', 'oai oái ', 'oái ', 'pho ', 'phè ', 'phè phè ', 'phía ', 'phía bên ', 'phía bạn ', 'phía dưới ', 'phía sau ', 'phía trong ', 'phía trên ', 'phía trước ', 'phóc ', 'phót ', 'phù hợp ', 'phăn phắt ', 'phương chi ', 'phải ', 'phải biết ', 'phải chi ', 'phải chăng ', 'phải cách ', 'phải cái ', 'phải giờ ', 'phải khi ', 'phải không ', 'phải lại ', 'phải lời ', 'phải người ', 'phải như ', 'phải rồi ', 'phải tay ', 'phần ', 'phần lớn ', 'phần nhiều ', 'phần nào ', 'phần sau ', 'phần việc ', 'phắt ', 'phỉ phui ', 'phỏng ', 'phỏng như ', 'phỏng nước ', 'phỏng theo ', 'phỏng tính ', 'phốc ', 'phụt ', 'phứt ', 'qua ', 'qua chuyện ', 'qua khỏi ', 'qua lại ', 'qua lần ', 'qua ngày ', 'qua tay ', 'qua thì ', 'qua đi ', 'quan trọng ', 'quan trọng vấn đề ', 'quan tâm ', 'quay ', 'quay bước ', 'quay lại ', 'quay số ', 'quay đi ', 'quá ', 'quá bán ', 'quá bộ ', 'quá giờ ', 'quá lời ', 'quá mức ', 'quá nhiều ', 'quá tay ', 'quá thì ', 'quá tin ', 'quá trình ', 'quá tuổi ', 'quá đáng ', 'quá ư ', 'quả ', 'quả là ', 'quả thật ', 'quả thế ', 'quả vậy ', 'quận ', 'ra ', 'ra bài ', 'ra bộ ', 'ra chơi ', 'ra gì ', 'ra lại ', 'ra lời ', 'ra ngôi ', 'ra người ', 'ra sao ', 'ra tay ', 'ra vào ', 'ra ý ', 'ra điều ', 'ra đây ', 'ren rén ', 'riu ríu ', 'riêng ', 'riêng từng ', 'riệt ', 'rày ', 'ráo ', 'ráo cả ', 'ráo nước ', 'ráo trọi ', 'rén ', 'rén bước ', 'rích ', 'rón rén ', 'rõ ', 'rõ là ', 'rõ thật ', 'rút cục ', 'răng ', 'răng răng ', 'rất ', 'rất lâu ', 'rằng ', 'rằng là ', 'rốt cuộc ', 'rốt cục ', 'rồi ', 'rồi nữa ', 'rồi ra ', 'rồi sao ', 'rồi sau ', 'rồi tay ', 'rồi thì ', 'rồi xem ', 'rồi đây ', 'rứa ', 'sa sả ', 'sang ', 'sang năm ', 'sang sáng ', 'sang tay ', 'sao ', 'sao bản ', 'sao bằng ', 'sao cho ', 'sao vậy ', 'sao đang ', 'sau ', 'sau chót ', 'sau cuối ', 'sau cùng ', 'sau hết ', 'sau này ', 'sau nữa ', 'sau sau ', 'sau đây ', 'sau đó ', 'so ', 'so với ', 'song le ', 'suýt ', 'suýt nữa ', 'sáng ', 'sáng ngày ', 'sáng rõ ', 'sáng thế ', 'sáng ý ', 'sì ', 'sì sì ', 'sất ', 'sắp ', 'sắp đặt ', 'sẽ ', 'sẽ biết ', 'sẽ hay ', 'số ', 'số cho biết ', 'số cụ thể ', 'số loại ', 'số là ', 'số người ', 'số phần ', 'số thiếu ', 'sốt sột ', 'sớm ', 'sớm ngày ', 'sở dĩ ', 'sử dụng ', 'sự ', 'sự thế ', 'sự việc ', 'tanh ', 'tanh tanh ', 'tay ', 'tay quay ', 'tha hồ ', 'tha hồ chơi ', 'tha hồ ăn ', 'than ôi ', 'thanh ', 'thanh ba ', 'thanh chuyển ', 'thanh không ', 'thanh thanh ', 'thanh tính ', 'thanh điều kiện ', 'thanh điểm ', 'thay đổi ', 'thay đổi tình trạng ', 'theo ', 'theo bước ', 'theo như ', 'theo tin ', 'thi thoảng ', 'thiếu ', 'thiếu gì ', 'thiếu điểm ', 'thoạt ', 'thoạt nghe ', 'thoạt nhiên ', 'thoắt ', 'thuần ', 'thuần ái ', 'thuộc ', 'thuộc bài ', 'thuộc cách ', 'thuộc lại ', 'thuộc từ ', 'thà ', 'thà là ', 'thà rằng ', 'thành ra ', 'thành thử ', 'thái quá ', 'tháng ', 'tháng ngày ', 'tháng năm ', 'tháng tháng ', 'thêm ', 'thêm chuyện ', 'thêm giờ ', 'thêm vào ', 'thì ', 'thì giờ ', 'thì là ', 'thì phải ', 'thì ra ', 'thì thôi ', 'thình lình ', 'thích ', 'thích cứ ', 'thích thuộc ', 'thích tự ', 'thích ý ', 'thím ', 'thôi ', 'thôi việc ', 'thúng thắng ', 'thương ôi ', 'thường ', 'thường bị ', 'thường hay ', 'thường khi ', 'thường số ', 'thường sự ', 'thường thôi ', 'thường thường ', 'thường tính ', 'thường tại ', 'thường xuất hiện ', 'thường đến ', 'thảo hèn ', 'thảo nào ', 'thấp ', 'thấp cơ ', 'thấp thỏm ', 'thấp xuống ', 'thấy ', 'thấy tháng ', 'thẩy ', 'thậm ', 'thậm chí ', 'thậm cấp ', 'thậm từ ', 'thật ', 'thật chắc ', 'thật là ', 'thật lực ', 'thật quả ', 'thật ra ', 'thật sự ', 'thật thà ', 'thật tốt ', 'thật vậy ', 'thế ', 'thế chuẩn bị ', 'thế là ', 'thế lại ', 'thế mà ', 'thế nào ', 'thế nên ', 'thế ra ', 'thế sự ', 'thế thì ', 'thế thôi ', 'thế thường ', 'thế thế ', 'thế à ', 'thế đó ', 'thếch ', 'thỉnh thoảng ', 'thỏm ', 'thốc ', 'thốc tháo ', 'thốt ', 'thốt nhiên ', 'thốt nói ', 'thốt thôi ', 'thộc ', 'thời gian ', 'thời gian sử dụng ', 'thời gian tính ', 'thời điểm ', 'thục mạng ', 'thứ ', 'thứ bản ', 'thứ đến ', 'thửa ', 'thực hiện ', 'thực hiện đúng ', 'thực ra ', 'thực sự ', 'thực tế ', 'thực vậy ', 'tin ', 'tin thêm ', 'tin vào ', 'tiếp theo ', 'tiếp tục ', 'tiếp đó ', 'tiện thể ', 'toà ', 'toé khói ', 'toẹt ', 'trong ', 'trong khi ', 'trong lúc ', 'trong mình ', 'trong ngoài ', 'trong này ', 'trong số ', 'trong vùng ', 'trong đó ', 'trong ấy ', 'tránh ', 'tránh khỏi ', 'tránh ra ', 'tránh tình trạng ', 'tránh xa ', 'trên ', 'trên bộ ', 'trên dưới ', 'trước ', 'trước hết ', 'trước khi ', 'trước kia ', 'trước nay ', 'trước ngày ', 'trước nhất ', 'trước sau ', 'trước tiên ', 'trước tuổi ', 'trước đây ', 'trước đó ', 'trả ', 'trả của ', 'trả lại ', 'trả ngay ', 'trả trước ', 'trếu tráo ', 'trển ', 'trệt ', 'trệu trạo ', 'trỏng ', 'trời đất ơi ', 'trở thành ', 'trừ phi ', 'trực tiếp ', 'trực tiếp làm ', 'tuy ', 'tuy có ', 'tuy là ', 'tuy nhiên ', 'tuy rằng ', 'tuy thế ', 'tuy vậy ', 'tuy đã ', 'tuyệt nhiên ', 'tuần tự ', 'tuốt luốt ', 'tuốt tuồn tuột ', 'tuốt tuột ', 'tuổi ', 'tuổi cả ', 'tuổi tôi ', 'tà tà ', 'tên ', 'tên chính ', 'tên cái ', 'tên họ ', 'tên tự ', 'tênh ', 'tênh tênh ', 'tìm ', 'tìm bạn ', 'tìm cách ', 'tìm hiểu ', 'tìm ra ', 'tìm việc ', 'tình trạng ', 'tính ', 'tính cách ', 'tính căn ', 'tính người ', 'tính phỏng ', 'tính từ ', 'tít mù ', 'tò te ', 'tôi ', 'tôi con ', 'tông tốc ', 'tù tì ', 'tăm tắp ', 'tăng ', 'tăng chúng ', 'tăng cấp ', 'tăng giảm ', 'tăng thêm ', 'tăng thế ', 'tại ', 'tại lòng ', 'tại nơi ', 'tại sao ', 'tại tôi ', 'tại vì ', 'tại đâu ', 'tại đây ', 'tại đó ', 'tạo ', 'tạo cơ hội ', 'tạo nên ', 'tạo ra ', 'tạo ý ', 'tạo điều kiện ', 'tấm ', 'tấm bản ', 'tấm các ', 'tấn ', 'tấn tới ', 'tất cả ', 'tất cả bao nhiêu ', 'tất thảy ', 'tất tần tật ', 'tất tật ', 'tập trung ', 'tắp ', 'tắp lự ', 'tắp tắp ', 'tọt ', 'tỏ ra ', 'tỏ vẻ ', 'tốc tả ', 'tối ư ', 'tốt ', 'tốt bạn ', 'tốt bộ ', 'tốt hơn ', 'tốt mối ', 'tốt ngày ', 'tột ', 'tột cùng ', 'tớ ', 'tới ', 'tới gần ', 'tới mức ', 'tới nơi ', 'tới thì ', 'tức thì ', 'tức tốc ', 'từ ', 'từ căn ', 'từ giờ ', 'từ khi ', 'từ loại ', 'từ nay ', 'từ thế ', 'từ tính ', 'từ tại ', 'từ từ ', 'từ ái ', 'từ điều ', 'từ đó ', 'từ ấy ', 'từng ', 'từng cái ', 'từng giờ ', 'từng nhà ', 'từng phần ', 'từng thời gian ', 'từng đơn vị ', 'từng ấy ', 'tự ', 'tự cao ', 'tự khi ', 'tự lượng ', 'tự tính ', 'tự tạo ', 'tự vì ', 'tự ý ', 'tự ăn ', 'tựu trung ', 'veo ', 'veo veo ', 'việc ', 'việc gì ', 'vung thiên địa ', 'vung tàn tán ', 'vung tán tàn ', 'và ', 'vài ', 'vài ba ', 'vài người ', 'vài nhà ', 'vài nơi ', 'vài tên ', 'vài điều ', 'vào ', 'vào gặp ', 'vào khoảng ', 'vào lúc ', 'vào vùng ', 'vào đến ', 'vâng ', 'vâng chịu ', 'vâng dạ ', 'vâng vâng ', 'vâng ý ', 'vèo ', 'vèo vèo ', 'vì ', 'vì chưng ', 'vì rằng ', 'vì sao ', 'vì thế ', 'vì vậy ', 'ví bằng ', 'ví dù ', 'ví phỏng ', 'ví thử ', 'vô hình trung ', 'vô kể ', 'vô luận ', 'vô vàn ', 'vùng ', 'vùng lên ', 'vùng nước ', 'văng tê ', 'vượt ', 'vượt khỏi ', 'vượt quá ', 'vạn nhất ', 'vả chăng ', 'vả lại ', 'vấn đề ', 'vấn đề quan trọng ', 'vẫn ', 'vẫn thế ', 'vậy ', 'vậy là ', 'vậy mà ', 'vậy nên ', 'vậy ra ', 'vậy thì ', 'vậy ư ', 'về ', 'về không ', 'về nước ', 'về phần ', 'về sau ', 'về tay ', 'vị trí ', 'vị tất ', 'vốn dĩ ', 'với ', 'với lại ', 'với nhau ', 'vở ', 'vụt ', 'vừa ', 'vừa khi ', 'vừa lúc ', 'vừa mới ', 'vừa qua ', 'vừa rồi ', 'vừa vừa ', 'xa ', 'xa cách ', 'xa gần ', 'xa nhà ', 'xa tanh ', 'xa tắp ', 'xa xa ', 'xa xả ', 'xem ', 'xem lại ', 'xem ra ', 'xem số ', 'xin ', 'xin gặp ', 'xin vâng ', 'xiết bao ', 'xon xón ', 'xoành xoạch ', 'xoét ', 'xoẳn ', 'xoẹt ', 'xuất hiện ', 'xuất kì bất ý ', 'xuất kỳ bất ý ', 'xuể ', 'xuống ', 'xăm xúi ', 'xăm xăm ', 'xăm xắm ', 'xảy ra ', 'xềnh xệch ', 'xệp ', 'xử lý ', 'yêu cầu ', 'à ', 'à này ', 'à ơi ', 'ào ', 'ào vào ', 'ào ào ', 'á ', 'á à ', 'ái ', 'ái chà ', 'ái dà ', 'áng ', 'áng như ', 'âu là ', 'ít ', 'ít biết ', 'ít có ', 'ít hơn ', 'ít khi ', 'ít lâu ', 'ít nhiều ', 'ít nhất ', 'ít nữa ', 'ít quá ', 'ít ra ', 'ít thôi ', 'ít thấy ', 'ô hay ', 'ô hô ', 'ô kê ', 'ô kìa ', 'ôi chao ', 'ôi thôi ', 'ông ', 'ông nhỏ ', 'ông tạo ', 'ông từ ', 'ông ấy ', 'ông ổng ', 'úi ', 'úi chà ', 'úi dào ', 'ý ', 'ý chừng ', 'ý da ', 'ý hoặc ', 'ăn ', 'ăn chung ', 'ăn chắc ', 'ăn chịu ', 'ăn cuộc ', 'ăn hết ', 'ăn hỏi ', 'ăn làm ', 'ăn người ', 'ăn ngồi ', 'ăn quá ', 'ăn riêng ', 'ăn sáng ', 'ăn tay ', 'ăn trên ', 'ăn về ', 'đang ', 'đang tay ', 'đang thì ', 'điều ', 'điều gì ', 'điều kiện ', 'điểm ', 'điểm chính ', 'điểm gặp ', 'điểm đầu tiên ', 'đành đạch ', 'đáng ', 'đáng kể ', 'đáng lí ', 'đáng lý ', 'đáng lẽ ', 'đáng số ', 'đánh giá ', 'đánh đùng ', 'đáo để ', 'đâu ', 'đâu có ', 'đâu cũng ', 'đâu như ', 'đâu nào ', 'đâu phải ', 'đâu đâu ', 'đâu đây ', 'đâu đó ', 'đây ', 'đây này ', 'đây rồi ', 'đây đó ', 'đã ', 'đã hay ', 'đã không ', 'đã là ', 'đã lâu ', 'đã thế ', 'đã vậy ', 'đã đủ ', 'đó ', 'đó đây ', 'đúng ', 'đúng ngày ', 'đúng ra ', 'đúng tuổi ', 'đúng với ', 'đơn vị ', 'đưa ', 'đưa cho ', 'đưa chuyện ', 'đưa em ', 'đưa ra ', 'đưa tay ', 'đưa tin ', 'đưa tới ', 'đưa vào ', 'đưa về ', 'đưa xuống ', 'đưa đến ', 'được ', 'được cái ', 'được lời ', 'được nước ', 'được tin ', 'đại loại ', 'đại nhân ', 'đại phàm ', 'đại để ', 'đạt ', 'đảm bảo ', 'đầu tiên ', 'đầy ', 'đầy năm ', 'đầy phè ', 'đầy tuổi ', 'đặc biệt ', 'đặt ', 'đặt làm ', 'đặt mình ', 'đặt mức ', 'đặt ra ', 'đặt trước ', 'đặt để ', 'đến ', 'đến bao giờ ', 'đến cùng ', 'đến cùng cực ', 'đến cả ', 'đến giờ ', 'đến gần ', 'đến hay ', 'đến khi ', 'đến lúc ', 'đến lời ', 'đến nay ', 'đến ngày ', 'đến nơi ', 'đến nỗi ', 'đến thì ', 'đến thế ', 'đến tuổi ', 'đến xem ', 'đến điều ', 'đến đâu ', 'đều ', 'đều bước ', 'đều nhau ', 'đều đều ', 'để ', 'để cho ', 'để giống ', 'để không ', 'để lòng ', 'để lại ', 'để mà ', 'để phần ', 'để được ', 'để đến nỗi ', 'đối với ', 'đồng thời ', 'đủ ', 'đủ dùng ', 'đủ nơi ', 'đủ số ', 'đủ điều ', 'đủ điểm ', 'ơ ', 'ơ hay ', 'ơ kìa ', 'ơi ', 'ơi là ', 'ư ', 'ạ ', 'ạ ơi ', 'ấy ', 'ấy là ', 'ầu ơ ', 'ắt ', 'ắt hẳn ', 'ắt là ', 'ắt phải ', 'ắt thật ', 'ối dào ', 'ối giời ', 'ối giời ơi ', 'ồ ', 'ồ ồ ', 'ổng ', 'ớ ', 'ớ này ', 'ờ ', 'ờ ờ ', 'ở ', 'ở lại ', 'ở như ', 'ở nhờ ', 'ở năm ', 'ở trên ', 'ở vào ', 'ở đây ', 'ở đó ', 'ở được ', 'ủa ', 'ứ hự ', 'ứ ừ ', 'ừ ', 'ừ nhé ', 'ừ thì ', 'ừ ào ', 'ừ ừ ', 'ử']}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'bow__ngram_range': [(1, 1), (1, 3), (1, 5)],\n",
        "    'bow__stop_words': [STOPWORDS, None],\n",
        "    'bow__max_df': [0.5, 0.75, 1.0],\n",
        "    'bow__min_df': [2, 3, 4]\n",
        "}\n",
        "\n",
        "# Define the pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('bow', CountVectorizer()),\n",
        "    ('ovr', OneVsRestClassifier(LogisticRegression(random_state = 42)))\n",
        "])\n",
        "\n",
        "# Initialize the grid search\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Print the best parameters\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gz0IRfwt2NB1"
      },
      "outputs": [],
      "source": [
        "bow = CountVectorizer(ngram_range=(1, 3), tokenizer=word_tokenize, stop_words=STOPWORDS,max_df=0.75, min_df=2)\n",
        "X_train_bow = bow.fit_transform(X_train)\n",
        "X_test_bow = bow.transform(X_test)\n",
        "\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=STOPWORDS,max_df=0.75, min_df=4, smooth_idf=True)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwHsduhwlotm",
        "outputId": "eb2d1cab-f2e5-4d5f-e37e-63c50469a890"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(12240, 40385)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_bow.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUR9yVJwm7OA",
        "outputId": "cc01898c-dd9a-4ddf-b306-9666370f389d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<12240x2724 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 190383 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgCXWMoh4Ton"
      },
      "outputs": [],
      "source": [
        "rdrsegmenter = VnCoreNLP(\"/content/drive/MyDrive/transformers/vncorenlp/VnCoreNLP-1.1.1.jar\", annotators=\"wseg\", max_heap_size='-Xmx500m')\n",
        "\n",
        "X_train_tokenized = [rdrsegmenter.tokenize(corpus)[0] for corpus in X_train.values]\n",
        "X_test_tokenized = [rdrsegmenter.tokenize(corpus)[0] for corpus in X_test.values]\n",
        "vs = 150 # number of dimensions that our words are going to be embedded in\n",
        "context_size = 5 # context window\n",
        "min_word = 10 # minimal number of occurence to be included in the embedded corpus\n",
        "\n",
        "skipgram = word2vec.Word2Vec(X_train_tokenized, vector_size = vs, \\\n",
        "                            window=context_size, min_count=min_word, \\\n",
        "                            epochs=50, seed=42, sg = 1)\n",
        "\n",
        "vs_cbow = 150 # number of dimensions that our words are going to be embedded in\n",
        "context_size_cbow = 5 # context window\n",
        "\n",
        "cbow = word2vec.Word2Vec(X_train_tokenized, vector_size = vs_cbow, \\\n",
        "                            window=context_size_cbow, min_count=min_word, \\\n",
        "                            epochs=50, seed=42, sg = 0)\n",
        "\n",
        "# Get words and indexes from the word2vec model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4k4btqH_XKR"
      },
      "outputs": [],
      "source": [
        "word_vec_unpack = [(word, idx) for word, idx in \\\n",
        "                   skipgram.wv.key_to_index.items()]\n",
        "tokens, indexes = zip(*word_vec_unpack)\n",
        "word_vec_df = pd.DataFrame(skipgram.wv.vectors[indexes, :], index=tokens)\n",
        "X_train_skipgram = np.array([word_vec_df.loc[list(set(doc).intersection(set(word_vec_df.index)))].mean(axis=0) for doc in X_train_tokenized])\n",
        "X_test_skipgram = np.array([word_vec_df.loc[list(set(doc).intersection(set(word_vec_df.index)))].mean(axis=0) for doc in X_test_tokenized])\n",
        "\n",
        "\n",
        "word_vec_unpack = [(word, idx) for word, idx in \\\n",
        "                   cbow.wv.key_to_index.items()]\n",
        "tokens, indexes = zip(*word_vec_unpack)\n",
        "word_vec_df = pd.DataFrame(cbow.wv.vectors[indexes, :], index=tokens)\n",
        "X_train_cbow = np.array([word_vec_df.loc[list(set(doc).intersection(set(word_vec_df.index)))].mean(axis=0) for doc in X_train_tokenized])\n",
        "X_test_cbow = np.array([word_vec_df.loc[list(set(doc).intersection(set(word_vec_df.index)))].mean(axis=0) for doc in X_test_tokenized])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7H97IKw-irl"
      },
      "outputs": [],
      "source": [
        "X_train_skipgram = pd.DataFrame(X_train_skipgram).fillna(0)\n",
        "X_test_skipgram = pd.DataFrame(X_test_skipgram).fillna(0)\n",
        "X_train_cbow = pd.DataFrame(X_train_cbow).fillna(0)\n",
        "X_test_cbow = pd.DataFrame(X_test_cbow).fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aV3x0fn6RoP"
      },
      "outputs": [],
      "source": [
        "lr_model = LogisticRegression()\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "nb_model = MultinomialNB()\n",
        "sgd = SGDClassifier(loss='hinge', penalty='l2',\n",
        "  alpha=1e-3, random_state=42,\n",
        "  max_iter=5, tol=None)\n",
        "\n",
        "\n",
        "models_list = [(\"Logistic Regression\", lr_model), (\"XGBoost\", xgb_model), (\"Naive Bayes\", nb_model), (\"SVM\", sgd)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RAdWyIHZcPn"
      },
      "source": [
        "# 1. Evaluate Bow models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9OSOQZU99ga",
        "outputId": "28d4ec45-aac6-4936-f003-b573ee3894a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating Logistic Regression\n",
            "Classification report from One Vs Rest model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.93      2721\n",
            "           1       0.97      0.91      0.94       581\n",
            "           2       0.92      0.78      0.84       518\n",
            "           3       0.93      0.89      0.91      1366\n",
            "           4       0.96      0.83      0.89       509\n",
            "           5       0.87      0.77      0.81       309\n",
            "\n",
            "   micro avg       0.93      0.90      0.91      6004\n",
            "   macro avg       0.93      0.86      0.89      6004\n",
            "weighted avg       0.93      0.90      0.91      6004\n",
            " samples avg       0.91      0.90      0.89      6004\n",
            "\n",
            "Hamming Loss:  0.051\n",
            "Classification report from Ensemble model from classifier chain\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.95      0.93      2721\n",
            "           1       0.97      0.91      0.94       581\n",
            "           2       0.92      0.79      0.85       518\n",
            "           3       0.93      0.90      0.91      1366\n",
            "           4       0.96      0.83      0.89       509\n",
            "           5       0.87      0.77      0.82       309\n",
            "\n",
            "   micro avg       0.92      0.90      0.91      6004\n",
            "   macro avg       0.93      0.86      0.89      6004\n",
            "weighted avg       0.92      0.90      0.91      6004\n",
            " samples avg       0.91      0.90      0.90      6004\n",
            "\n",
            "Hamming Loss:  0.051\n",
            "evaluating XGBoost\n",
            "Classification report from One Vs Rest model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.93      2721\n",
            "           1       0.95      0.93      0.94       581\n",
            "           2       0.89      0.82      0.85       518\n",
            "           3       0.92      0.93      0.92      1366\n",
            "           4       0.96      0.88      0.92       509\n",
            "           5       0.84      0.72      0.78       309\n",
            "\n",
            "   micro avg       0.91      0.91      0.91      6004\n",
            "   macro avg       0.91      0.87      0.89      6004\n",
            "weighted avg       0.91      0.91      0.91      6004\n",
            " samples avg       0.89      0.90      0.89      6004\n",
            "\n",
            "Hamming Loss:  0.052\n",
            "Classification report from Ensemble model from classifier chain\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93      2721\n",
            "           1       0.95      0.93      0.94       581\n",
            "           2       0.90      0.82      0.86       518\n",
            "           3       0.92      0.93      0.93      1366\n",
            "           4       0.96      0.88      0.92       509\n",
            "           5       0.86      0.71      0.78       309\n",
            "\n",
            "   micro avg       0.91      0.92      0.92      6004\n",
            "   macro avg       0.91      0.87      0.89      6004\n",
            "weighted avg       0.91      0.92      0.92      6004\n",
            " samples avg       0.91      0.91      0.90      6004\n",
            "\n",
            "Hamming Loss:  0.05\n",
            "evaluating Naive Bayes\n",
            "Classification report from One Vs Rest model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.91      2721\n",
            "           1       0.68      0.85      0.76       581\n",
            "           2       0.73      0.75      0.74       518\n",
            "           3       0.74      0.88      0.81      1366\n",
            "           4       0.87      0.76      0.81       509\n",
            "           5       0.86      0.48      0.62       309\n",
            "\n",
            "   micro avg       0.81      0.87      0.84      6004\n",
            "   macro avg       0.79      0.78      0.77      6004\n",
            "weighted avg       0.81      0.87      0.84      6004\n",
            " samples avg       0.81      0.87      0.82      6004\n",
            "\n",
            "Hamming Loss:  0.099\n",
            "Classification report from Ensemble model from classifier chain\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91      2721\n",
            "           1       0.68      0.85      0.76       581\n",
            "           2       0.74      0.75      0.74       518\n",
            "           3       0.74      0.88      0.81      1366\n",
            "           4       0.88      0.75      0.81       509\n",
            "           5       0.87      0.48      0.62       309\n",
            "\n",
            "   micro avg       0.81      0.87      0.84      6004\n",
            "   macro avg       0.80      0.78      0.78      6004\n",
            "weighted avg       0.81      0.87      0.84      6004\n",
            " samples avg       0.81      0.87      0.82      6004\n",
            "\n",
            "Hamming Loss:  0.099\n",
            "evaluating SVM\n",
            "Classification report from One Vs Rest model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.93      2721\n",
            "           1       0.97      0.91      0.94       581\n",
            "           2       0.92      0.76      0.83       518\n",
            "           3       0.92      0.93      0.92      1366\n",
            "           4       0.97      0.81      0.88       509\n",
            "           5       0.90      0.49      0.63       309\n",
            "\n",
            "   micro avg       0.93      0.88      0.91      6004\n",
            "   macro avg       0.93      0.81      0.86      6004\n",
            "weighted avg       0.93      0.88      0.90      6004\n",
            " samples avg       0.89      0.87      0.87      6004\n",
            "\n",
            "Hamming Loss:  0.054\n",
            "Classification report from Ensemble model from classifier chain\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.96      0.92      2721\n",
            "           1       0.97      0.91      0.94       581\n",
            "           2       0.93      0.77      0.85       518\n",
            "           3       0.92      0.92      0.92      1366\n",
            "           4       0.96      0.83      0.89       509\n",
            "           5       0.90      0.52      0.66       309\n",
            "\n",
            "   micro avg       0.91      0.90      0.90      6004\n",
            "   macro avg       0.93      0.82      0.86      6004\n",
            "weighted avg       0.91      0.90      0.90      6004\n",
            " samples avg       0.90      0.89      0.88      6004\n",
            "\n",
            "Hamming Loss:  0.056\n"
          ]
        }
      ],
      "source": [
        "# bow evaluation\n",
        "\n",
        "\n",
        "score_dict = {}\n",
        "for name, model in models_list:\n",
        "  if name == \"SVM\":\n",
        "    predict_proba = 0\n",
        "  else:\n",
        "    predict_proba = 1\n",
        "  print(f\"evaluating {name}\")\n",
        "  score_dict[name] = evaluate_chain(model, X_train_bow, y_train, X_test_bow, y_test, predict_proba = predict_proba)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o-SGv4pZjn7"
      },
      "source": [
        "# 2. TFIDF evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDbFLB_nFoKG",
        "outputId": "bb393838-c34f-4ce8-d4af-12826965f2ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating Logistic Regression\n",
            "Classification report from One Vs Rest model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.97      0.93      2721\n",
            "           1       0.98      0.84      0.90       581\n",
            "           2       0.93      0.68      0.78       518\n",
            "           3       0.93      0.87      0.90      1366\n",
            "           4       0.97      0.74      0.84       509\n",
            "           5       0.91      0.47      0.62       309\n",
            "\n",
            "   micro avg       0.92      0.86      0.89      6004\n",
            "   macro avg       0.94      0.76      0.83      6004\n",
            "weighted avg       0.93      0.86      0.89      6004\n",
            " samples avg       0.89      0.86      0.86      6004\n",
            "\n",
            "Hamming Loss:  0.062\n",
            "Classification report from Ensemble model from classifier chain\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.98      0.92      2721\n",
            "           1       0.97      0.84      0.90       581\n",
            "           2       0.92      0.68      0.78       518\n",
            "           3       0.93      0.87      0.90      1366\n",
            "           4       0.97      0.75      0.85       509\n",
            "           5       0.92      0.71      0.80       309\n",
            "\n",
            "   micro avg       0.91      0.88      0.89      6004\n",
            "   macro avg       0.93      0.80      0.86      6004\n",
            "weighted avg       0.91      0.88      0.89      6004\n",
            " samples avg       0.90      0.89      0.88      6004\n",
            "\n",
            "Hamming Loss:  0.062\n",
            "evaluating XGBoost\n",
            "Classification report from One Vs Rest model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.95      0.93      2721\n",
            "           1       0.95      0.93      0.94       581\n",
            "           2       0.89      0.80      0.84       518\n",
            "           3       0.92      0.93      0.93      1366\n",
            "           4       0.96      0.87      0.91       509\n",
            "           5       0.85      0.74      0.79       309\n",
            "\n",
            "   micro avg       0.91      0.92      0.91      6004\n",
            "   macro avg       0.91      0.87      0.89      6004\n",
            "weighted avg       0.91      0.92      0.91      6004\n",
            " samples avg       0.90      0.91      0.89      6004\n",
            "\n",
            "Hamming Loss:  0.05\n",
            "Classification report from Ensemble model from classifier chain\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93      2721\n",
            "           1       0.94      0.93      0.94       581\n",
            "           2       0.90      0.81      0.85       518\n",
            "           3       0.92      0.93      0.92      1366\n",
            "           4       0.96      0.87      0.91       509\n",
            "           5       0.85      0.75      0.80       309\n",
            "\n",
            "   micro avg       0.91      0.92      0.91      6004\n",
            "   macro avg       0.91      0.88      0.89      6004\n",
            "weighted avg       0.91      0.92      0.91      6004\n",
            " samples avg       0.91      0.92      0.90      6004\n",
            "\n",
            "Hamming Loss:  0.051\n",
            "evaluating Naive Bayes\n",
            "Classification report from One Vs Rest model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.99      0.91      2721\n",
            "           1       0.94      0.60      0.73       581\n",
            "           2       0.95      0.41      0.58       518\n",
            "           3       0.77      0.75      0.76      1366\n",
            "           4       0.99      0.29      0.45       509\n",
            "           5       0.93      0.30      0.45       309\n",
            "\n",
            "   micro avg       0.84      0.75      0.79      6004\n",
            "   macro avg       0.90      0.56      0.64      6004\n",
            "weighted avg       0.86      0.75      0.76      6004\n",
            " samples avg       0.83      0.77      0.77      6004\n",
            "\n",
            "Hamming Loss:  0.116\n",
            "Classification report from Ensemble model from classifier chain\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.99      0.91      2721\n",
            "           1       0.94      0.62      0.75       581\n",
            "           2       0.95      0.45      0.61       518\n",
            "           3       0.75      0.76      0.76      1366\n",
            "           4       0.99      0.31      0.47       509\n",
            "           5       0.94      0.35      0.51       309\n",
            "\n",
            "   micro avg       0.83      0.77      0.80      6004\n",
            "   macro avg       0.90      0.58      0.67      6004\n",
            "weighted avg       0.86      0.77      0.78      6004\n",
            " samples avg       0.83      0.79      0.78      6004\n",
            "\n",
            "Hamming Loss:  0.113\n",
            "evaluating SVM\n",
            "Classification report from One Vs Rest model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90      2721\n",
            "           1       0.98      0.78      0.87       581\n",
            "           2       0.97      0.49      0.65       518\n",
            "           3       0.93      0.85      0.89      1366\n",
            "           4       0.97      0.59      0.73       509\n",
            "           5       0.94      0.15      0.25       309\n",
            "\n",
            "   micro avg       0.88      0.82      0.85      6004\n",
            "   macro avg       0.94      0.64      0.72      6004\n",
            "weighted avg       0.89      0.82      0.83      6004\n",
            " samples avg       0.85      0.82      0.81      6004\n",
            "\n",
            "Hamming Loss:  0.087\n",
            "Classification report from Ensemble model from classifier chain\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      1.00      0.90      2721\n",
            "           1       0.98      0.79      0.88       581\n",
            "           2       0.97      0.49      0.65       518\n",
            "           3       0.93      0.86      0.89      1366\n",
            "           4       0.97      0.60      0.74       509\n",
            "           5       0.92      0.16      0.27       309\n",
            "\n",
            "   micro avg       0.87      0.82      0.85      6004\n",
            "   macro avg       0.93      0.65      0.72      6004\n",
            "weighted avg       0.89      0.82      0.83      6004\n",
            " samples avg       0.85      0.82      0.82      6004\n",
            "\n",
            "Hamming Loss:  0.088\n"
          ]
        }
      ],
      "source": [
        "# tfidf evaluation\n",
        "score_dict = {}\n",
        "for name, model in models_list:\n",
        "  if name == \"SVM\":\n",
        "    predict_proba = 0\n",
        "  else:\n",
        "    predict_proba = 1\n",
        "  print(f\"evaluating {name}\")\n",
        "  score_dict[name] = evaluate_chain(model, X_train_tfidf, y_train, X_test_tfidf, y_test, predict_proba = predict_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Op49o__Znh_"
      },
      "source": [
        "# 3. Word2vec (Skipgram) evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGSg4Gn0MgrV",
        "outputId": "8fa19cae-fe20-497e-9e9e-d6be604af65e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating Logistic Regression\n",
            "Classification report from One Vs Rest model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.96      0.92      2721\n",
            "           1       0.89      0.73      0.81       581\n",
            "           2       0.83      0.56      0.67       518\n",
            "           3       0.86      0.79      0.82      1366\n",
            "           4       0.85      0.55      0.67       509\n",
            "           5       0.86      0.68      0.76       309\n",
            "\n",
            "   micro avg       0.87      0.81      0.84      6004\n",
            "   macro avg       0.86      0.71      0.77      6004\n",
            "weighted avg       0.87      0.81      0.84      6004\n",
            " samples avg       0.87      0.84      0.83      6004\n",
            "\n",
            "Hamming Loss:  0.089\n",
            "Classification report from Ensemble model from classifier chain\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.96      0.92      2721\n",
            "           1       0.90      0.73      0.81       581\n",
            "           2       0.84      0.58      0.68       518\n",
            "           3       0.87      0.79      0.83      1366\n",
            "           4       0.85      0.56      0.68       509\n",
            "           5       0.87      0.65      0.74       309\n",
            "\n",
            "   micro avg       0.88      0.82      0.85      6004\n",
            "   macro avg       0.87      0.71      0.78      6004\n",
            "weighted avg       0.88      0.82      0.84      6004\n",
            " samples avg       0.88      0.84      0.84      6004\n",
            "\n",
            "Hamming Loss:  0.087\n",
            "evaluating XGBoost\n",
            "Classification report from One Vs Rest model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93      2721\n",
            "           1       0.90      0.79      0.84       581\n",
            "           2       0.87      0.69      0.77       518\n",
            "           3       0.86      0.84      0.85      1366\n",
            "           4       0.87      0.68      0.76       509\n",
            "           5       0.92      0.69      0.79       309\n",
            "\n",
            "   micro avg       0.89      0.86      0.87      6004\n",
            "   macro avg       0.89      0.78      0.82      6004\n",
            "weighted avg       0.89      0.86      0.87      6004\n",
            " samples avg       0.88      0.87      0.86      6004\n",
            "\n",
            "Hamming Loss:  0.074\n",
            "Classification report from Ensemble model from classifier chain\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.98      0.93      2721\n",
            "           1       0.91      0.78      0.84       581\n",
            "           2       0.87      0.70      0.78       518\n",
            "           3       0.87      0.86      0.87      1366\n",
            "           4       0.90      0.69      0.78       509\n",
            "           5       0.92      0.71      0.80       309\n",
            "\n",
            "   micro avg       0.89      0.87      0.88      6004\n",
            "   macro avg       0.89      0.79      0.83      6004\n",
            "weighted avg       0.89      0.87      0.88      6004\n",
            " samples avg       0.89      0.88      0.87      6004\n",
            "\n",
            "Hamming Loss:  0.07\n",
            "evaluating SVM\n",
            "Classification report from One Vs Rest model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.98      0.92      2721\n",
            "           1       0.91      0.68      0.78       581\n",
            "           2       0.91      0.41      0.57       518\n",
            "           3       0.85      0.82      0.84      1366\n",
            "           4       0.90      0.50      0.64       509\n",
            "           5       0.91      0.62      0.74       309\n",
            "\n",
            "   micro avg       0.87      0.81      0.84      6004\n",
            "   macro avg       0.89      0.67      0.75      6004\n",
            "weighted avg       0.87      0.81      0.82      6004\n",
            " samples avg       0.87      0.83      0.83      6004\n",
            "\n",
            "Hamming Loss:  0.093\n",
            "Classification report from Ensemble model from classifier chain\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.99      0.92      2721\n",
            "           1       0.90      0.69      0.78       581\n",
            "           2       0.90      0.44      0.59       518\n",
            "           3       0.84      0.82      0.83      1366\n",
            "           4       0.88      0.52      0.66       509\n",
            "           5       0.91      0.62      0.73       309\n",
            "\n",
            "   micro avg       0.87      0.82      0.84      6004\n",
            "   macro avg       0.88      0.68      0.75      6004\n",
            "weighted avg       0.87      0.82      0.83      6004\n",
            " samples avg       0.88      0.84      0.83      6004\n",
            "\n",
            "Hamming Loss:  0.091\n"
          ]
        }
      ],
      "source": [
        "# word2vec (skipgram) evaluation\n",
        "models_list = [(\"Logistic Regression\", lr_model), (\"XGBoost\", xgb_model), (\"SVM\", sgd)]\n",
        "score_dict = {}\n",
        "for name, model in models_list:\n",
        "  if name == \"SVM\":\n",
        "    predict_proba = 0\n",
        "  else:\n",
        "    predict_proba = 1\n",
        "  print(f\"evaluating {name}\")\n",
        "  score_dict[name] = evaluate_chain(model, X_train_skipgram, y_train, X_test_skipgram, y_test, predict_proba = predict_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NdguAFWZt0I"
      },
      "source": [
        "# 4. Word2vec cbow evalutaion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT29UI0lRKev",
        "outputId": "4421264c-fddc-46e6-ce65-df2b557cbf04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating Logistic Regression\n",
            "Classification report from One Vs Rest model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.95      0.92      2721\n",
            "           1       0.92      0.82      0.87       581\n",
            "           2       0.84      0.66      0.74       518\n",
            "           3       0.89      0.85      0.87      1366\n",
            "           4       0.90      0.67      0.77       509\n",
            "           5       0.85      0.75      0.79       309\n",
            "\n",
            "   micro avg       0.89      0.86      0.87      6004\n",
            "   macro avg       0.88      0.78      0.83      6004\n",
            "weighted avg       0.89      0.86      0.87      6004\n",
            " samples avg       0.89      0.87      0.86      6004\n",
            "\n",
            "Hamming Loss:  0.074\n",
            "Classification report from Ensemble model from classifier chain\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93      2721\n",
            "           1       0.93      0.82      0.87       581\n",
            "           2       0.84      0.67      0.74       518\n",
            "           3       0.89      0.84      0.87      1366\n",
            "           4       0.89      0.69      0.78       509\n",
            "           5       0.87      0.72      0.79       309\n",
            "\n",
            "   micro avg       0.89      0.86      0.88      6004\n",
            "   macro avg       0.89      0.78      0.83      6004\n",
            "weighted avg       0.89      0.86      0.87      6004\n",
            " samples avg       0.89      0.87      0.86      6004\n",
            "\n",
            "Hamming Loss:  0.072\n",
            "evaluating XGBoost\n",
            "Classification report from One Vs Rest model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93      2721\n",
            "           1       0.92      0.80      0.86       581\n",
            "           2       0.87      0.69      0.77       518\n",
            "           3       0.88      0.86      0.87      1366\n",
            "           4       0.88      0.67      0.76       509\n",
            "           5       0.91      0.73      0.81       309\n",
            "\n",
            "   micro avg       0.90      0.86      0.88      6004\n",
            "   macro avg       0.90      0.79      0.83      6004\n",
            "weighted avg       0.90      0.86      0.88      6004\n",
            " samples avg       0.89      0.87      0.87      6004\n",
            "\n",
            "Hamming Loss:  0.07\n",
            "Classification report from Ensemble model from classifier chain\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.97      0.93      2721\n",
            "           1       0.93      0.81      0.87       581\n",
            "           2       0.89      0.73      0.80       518\n",
            "           3       0.89      0.87      0.88      1366\n",
            "           4       0.91      0.68      0.78       509\n",
            "           5       0.92      0.73      0.82       309\n",
            "\n",
            "   micro avg       0.90      0.87      0.89      6004\n",
            "   macro avg       0.91      0.80      0.85      6004\n",
            "weighted avg       0.90      0.87      0.89      6004\n",
            " samples avg       0.90      0.88      0.88      6004\n",
            "\n",
            "Hamming Loss:  0.065\n",
            "evaluating SVM\n",
            "Classification report from One Vs Rest model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.93      0.92      2721\n",
            "           1       0.94      0.79      0.86       581\n",
            "           2       0.81      0.63      0.71       518\n",
            "           3       0.88      0.87      0.87      1366\n",
            "           4       0.85      0.68      0.76       509\n",
            "           5       0.84      0.77      0.81       309\n",
            "\n",
            "   micro avg       0.89      0.85      0.87      6004\n",
            "   macro avg       0.87      0.78      0.82      6004\n",
            "weighted avg       0.89      0.85      0.86      6004\n",
            " samples avg       0.89      0.87      0.85      6004\n",
            "\n",
            "Hamming Loss:  0.076\n",
            "Classification report from Ensemble model from classifier chain\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.93      2721\n",
            "           1       0.93      0.80      0.86       581\n",
            "           2       0.84      0.63      0.72       518\n",
            "           3       0.89      0.87      0.88      1366\n",
            "           4       0.88      0.66      0.76       509\n",
            "           5       0.86      0.76      0.81       309\n",
            "\n",
            "   micro avg       0.89      0.85      0.87      6004\n",
            "   macro avg       0.88      0.78      0.82      6004\n",
            "weighted avg       0.89      0.85      0.87      6004\n",
            " samples avg       0.89      0.87      0.86      6004\n",
            "\n",
            "Hamming Loss:  0.072\n"
          ]
        }
      ],
      "source": [
        "# word2vec (cbow) evaluation\n",
        "score_dict = {}\n",
        "for name, model in models_list:\n",
        "  if name == \"SVM\":\n",
        "    predict_proba = 0\n",
        "  else:\n",
        "    predict_proba = 1\n",
        "  print(f\"evaluating {name}\")\n",
        "  score_dict[name] = evaluate_chain(model, X_train_cbow, y_train, X_test_cbow, y_test, predict_proba = predict_proba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEuhvCcCz1La"
      },
      "outputs": [],
      "source": [
        "phobert_test = pd.read_csv(\"/content/drive/MyDrive/Thesis: Topic Modelling/Code/Phobert result/phobert_test_feature.csv\").drop(\"Unnamed: 0\", axis = 1)\n",
        "phobert_train = pd.read_csv(\"/content/drive/MyDrive/Thesis: Topic Modelling/Code/Phobert result/phobert_train_feature.csv\").drop(\"Unnamed: 0\", axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLplNgLkj8zD",
        "outputId": "9cf80755-67e8-4e82-a665-1495f1dd4e39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(12240, 768)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "phobert_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-sRjbonZzsH"
      },
      "source": [
        "# 4. Evaluate embedding from Phobert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkOd-cNjE73L"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "save_best_path =  \"/content/drive/MyDrive/THESIS DSEB62: Product review analysis/Baseline-model/Phobertv2\" + \"/best.pth\"\n",
        "model = torch.load(save_best_path)\n",
        "embedder = model.roberta\n",
        "\n",
        "import random\n",
        "from tqdm import tqdm_notebook\n",
        "device = 'cuda'\n",
        "phobert = embedder.to(device)\n",
        "with torch.no_grad():\n",
        "    phobert.eval()\n",
        "    train_embedded_mean = []\n",
        "    train_embedded_pooling = []\n",
        "    for step, batch in tqdm_notebook(enumerate(train_dataloader)):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        last_hidden_layer = phobert(b_input_ids,\n",
        "        token_type_ids=None,\n",
        "        attention_mask=b_input_mask)\n",
        "        embedded_value_mean = torch.mean(last_hidden_layer[0], dim=1)\n",
        "        embedded_value_pool = last_hidden_layer[0]\n",
        "        train_embedded_mean.append(embedded_value_mean)\n",
        "        train_embedded_pooling.append(embedded_value_pool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p48N-683Kc-",
        "outputId": "722a06aa-5615-47f5-d9da-1d49ae432095"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "evaluating Logistic Regression\n",
            "Classification report from One Vs Rest model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97      2721\n",
            "           1       0.98      0.98      0.98       581\n",
            "           2       0.94      0.93      0.94       518\n",
            "           3       0.94      0.97      0.96      1366\n",
            "           4       0.97      0.96      0.97       509\n",
            "           5       0.95      0.95      0.95       309\n",
            "\n",
            "   micro avg       0.96      0.97      0.96      6004\n",
            "   macro avg       0.96      0.96      0.96      6004\n",
            "weighted avg       0.96      0.97      0.96      6004\n",
            " samples avg       0.96      0.97      0.96      6004\n",
            "\n",
            "Hamming Loss:  0.022\n",
            "Classification report from Ensemble model from classifier chain\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97      2721\n",
            "           1       0.98      0.98      0.98       581\n",
            "           2       0.94      0.93      0.94       518\n",
            "           3       0.94      0.97      0.95      1366\n",
            "           4       0.97      0.96      0.97       509\n",
            "           5       0.95      0.95      0.95       309\n",
            "\n",
            "   micro avg       0.96      0.97      0.96      6004\n",
            "   macro avg       0.96      0.96      0.96      6004\n",
            "weighted avg       0.96      0.97      0.96      6004\n",
            " samples avg       0.96      0.97      0.96      6004\n",
            "\n",
            "Hamming Loss:  0.023\n",
            "evaluating XGBoost\n",
            "Classification report from One Vs Rest model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96      2721\n",
            "           1       0.98      0.98      0.98       581\n",
            "           2       0.94      0.92      0.93       518\n",
            "           3       0.94      0.96      0.95      1366\n",
            "           4       0.97      0.97      0.97       509\n",
            "           5       0.96      0.94      0.95       309\n",
            "\n",
            "   micro avg       0.96      0.96      0.96      6004\n",
            "   macro avg       0.96      0.96      0.96      6004\n",
            "weighted avg       0.96      0.96      0.96      6004\n",
            " samples avg       0.96      0.96      0.95      6004\n",
            "\n",
            "Hamming Loss:  0.024\n",
            "Classification report from Ensemble model from classifier chain\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96      2721\n",
            "           1       0.98      0.98      0.98       581\n",
            "           2       0.94      0.92      0.93       518\n",
            "           3       0.94      0.96      0.95      1366\n",
            "           4       0.97      0.97      0.97       509\n",
            "           5       0.96      0.94      0.95       309\n",
            "\n",
            "   micro avg       0.96      0.96      0.96      6004\n",
            "   macro avg       0.96      0.96      0.96      6004\n",
            "weighted avg       0.96      0.96      0.96      6004\n",
            " samples avg       0.96      0.96      0.96      6004\n",
            "\n",
            "Hamming Loss:  0.024\n",
            "evaluating SVM\n",
            "Classification report from One Vs Rest model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      2721\n",
            "           1       0.98      0.98      0.98       581\n",
            "           2       0.95      0.92      0.93       518\n",
            "           3       0.94      0.97      0.95      1366\n",
            "           4       0.96      0.97      0.97       509\n",
            "           5       0.93      0.96      0.94       309\n",
            "\n",
            "   micro avg       0.95      0.97      0.96      6004\n",
            "   macro avg       0.95      0.96      0.96      6004\n",
            "weighted avg       0.95      0.97      0.96      6004\n",
            " samples avg       0.96      0.97      0.96      6004\n",
            "\n",
            "Hamming Loss:  0.024\n",
            "Classification report from Ensemble model from classifier chain\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97      2721\n",
            "           1       0.98      0.98      0.98       581\n",
            "           2       0.95      0.91      0.93       518\n",
            "           3       0.94      0.98      0.96      1366\n",
            "           4       0.96      0.97      0.97       509\n",
            "           5       0.94      0.96      0.95       309\n",
            "\n",
            "   micro avg       0.95      0.97      0.96      6004\n",
            "   macro avg       0.95      0.96      0.96      6004\n",
            "weighted avg       0.95      0.97      0.96      6004\n",
            " samples avg       0.96      0.97      0.96      6004\n",
            "\n",
            "Hamming Loss:  0.023\n"
          ]
        }
      ],
      "source": [
        "# phobert embedding evaluation\n",
        "score_dict = {}\n",
        "for name, model in models_list:\n",
        "  if name == \"SVM\":\n",
        "    predict_proba = 0\n",
        "  else:\n",
        "    predict_proba = 1\n",
        "  print(f\"evaluating {name}\")\n",
        "  score_dict[name] = evaluate_chain(model, phobert_train, y_train, phobert_test, y_test, predict_proba = predict_proba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7LITL_BFi4u"
      },
      "outputs": [],
      "source": [
        "lr = LogisticRegression()\n",
        "lr_trained = train_ovr(lr, phobert_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8Ku3W3lGBGL"
      },
      "outputs": [],
      "source": [
        "best_prediction = lr_trained.predict(phobert_test)\n",
        "best_proba = lr_trained.predict_proba(phobert_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7S0ysu02GUG6"
      },
      "outputs": [],
      "source": [
        "best_result_df = classification_report(y_test, best_prediction, target_names = y_test.columns, output_dict = True)\n",
        "pd.DataFrame(best_result_df).T.to_excel(\"best_result_df.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHa4nmMmNqO8",
        "outputId": "6fd0d7f2-8c6c-4530-a936-a102ff3c0bfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report from \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97      2721\n",
            "           1       0.98      0.98      0.98       581\n",
            "           2       0.94      0.93      0.94       518\n",
            "           3       0.94      0.97      0.96      1366\n",
            "           4       0.97      0.96      0.97       509\n",
            "           5       0.95      0.95      0.95       309\n",
            "\n",
            "   micro avg       0.96      0.97      0.96      6004\n",
            "   macro avg       0.96      0.96      0.96      6004\n",
            "weighted avg       0.96      0.97      0.96      6004\n",
            " samples avg       0.96      0.97      0.96      6004\n",
            "\n",
            "Hamming Loss:  0.022\n",
            "classification report of Quality\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.84      0.86       680\n",
            "           1       0.96      0.97      0.97      2721\n",
            "\n",
            "    accuracy                           0.95      3401\n",
            "   macro avg       0.92      0.91      0.91      3401\n",
            "weighted avg       0.94      0.95      0.95      3401\n",
            "\n",
            "classification report of Pack\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      2820\n",
            "           1       0.98      0.98      0.98       581\n",
            "\n",
            "    accuracy                           0.99      3401\n",
            "   macro avg       0.99      0.99      0.99      3401\n",
            "weighted avg       0.99      0.99      0.99      3401\n",
            "\n",
            "classification report of Serve\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      2883\n",
            "           1       0.94      0.93      0.94       518\n",
            "\n",
            "    accuracy                           0.98      3401\n",
            "   macro avg       0.97      0.96      0.96      3401\n",
            "weighted avg       0.98      0.98      0.98      3401\n",
            "\n",
            "classification report of Shipping\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97      2035\n",
            "           1       0.94      0.97      0.96      1366\n",
            "\n",
            "    accuracy                           0.96      3401\n",
            "   macro avg       0.96      0.97      0.96      3401\n",
            "weighted avg       0.96      0.96      0.96      3401\n",
            "\n",
            "classification report of Price\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99      2892\n",
            "           1       0.97      0.96      0.97       509\n",
            "\n",
            "    accuracy                           0.99      3401\n",
            "   macro avg       0.98      0.98      0.98      3401\n",
            "weighted avg       0.99      0.99      0.99      3401\n",
            "\n",
            "classification report of Other\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3092\n",
            "           1       0.95      0.95      0.95       309\n",
            "\n",
            "    accuracy                           0.99      3401\n",
            "   macro avg       0.98      0.98      0.98      3401\n",
            "weighted avg       0.99      0.99      0.99      3401\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate(y_test, best_prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "G9RjNZcdM0Rm",
        "outputId": "857e1d28-f65f-4e80-e331-97e4b8b60387"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "displayConfusionMatrix(y_test[\"Quality\"], best_prediction[:,0], label = \"'Quality'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcOZLn2UNALv"
      },
      "outputs": [],
      "source": [
        "def displayConfusionMatrix(y_true, y_pred, label = \"Dataset\"):\n",
        "    disp = ConfusionMatrixDisplay.from_predictions(\n",
        "        y_true,\n",
        "        y_pred, #np.argmax(y_pred, axis=1),\n",
        "        display_labels=[\"0\",\"1\"],\n",
        "        cmap=plt.cm.Blues\n",
        "    )\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    f1_score = tp / (tp+((fn+fp)/2))\n",
        "    disp.ax_.set_title(\"Confusion Matrix on \" + f\" {label} -- F1 Score: \" + str(f1_score.round(2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_7ZLrgGGyK-"
      },
      "outputs": [],
      "source": [
        "predict_proba_columns = [\"Predict_\" + i for i in y_test.columns]\n",
        "result_df = test.copy()\n",
        "result_df[predict_proba_columns] = best_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zP-z6TcCIL6q"
      },
      "outputs": [],
      "source": [
        "result_df.to_excel(\"best_prediction.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0QZSPAZ3yp4",
        "outputId": "6d0d9d7a-84be-4d9e-a556-349ef77ffdec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report from One Vs Rest model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      2721\n",
            "           1       0.98      0.98      0.98       581\n",
            "           2       0.95      0.92      0.93       518\n",
            "           3       0.94      0.97      0.95      1366\n",
            "           4       0.96      0.97      0.97       509\n",
            "           5       0.93      0.96      0.94       309\n",
            "\n",
            "   micro avg       0.95      0.97      0.96      6004\n",
            "   macro avg       0.95      0.96      0.96      6004\n",
            "weighted avg       0.95      0.97      0.96      6004\n",
            " samples avg       0.96      0.97      0.96      6004\n",
            "\n",
            "Hamming Loss:  0.024\n",
            "Classification report from Ensemble model from classifier chain\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97      2721\n",
            "           1       0.98      0.98      0.98       581\n",
            "           2       0.95      0.91      0.93       518\n",
            "           3       0.94      0.98      0.96      1366\n",
            "           4       0.96      0.97      0.97       509\n",
            "           5       0.94      0.96      0.95       309\n",
            "\n",
            "   micro avg       0.95      0.97      0.96      6004\n",
            "   macro avg       0.95      0.96      0.96      6004\n",
            "weighted avg       0.95      0.97      0.96      6004\n",
            " samples avg       0.96      0.97      0.96      6004\n",
            "\n",
            "Hamming Loss:  0.023\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.02362050377339998,\n",
              " 0.02342448299519749,\n",
              " 0.02298343624424189,\n",
              " 0.022885425855140643,\n",
              " 0.024355581691659314,\n",
              " 0.023277467411545624,\n",
              " 0.02401254532980496,\n",
              " 0.023669508967950604,\n",
              " 0.023277467411545624,\n",
              " 0.02381652455160247,\n",
              " 0.023473488189748114,\n",
              " 0.023130451827893757]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_chain(sgd, phobert_train, y_train, phobert_test, y_test, predict_proba = predict_proba)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}